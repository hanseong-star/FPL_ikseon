{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c2bc90",
   "metadata": {},
   "source": [
    "FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40db64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/hanseong/vscode/ML_code/FPL/FPL\n",
      "SRC_DIR: /home/hanseong/vscode/ML_code/FPL/FPL/src\n",
      "SRC exists?: True\n",
      "sys.path[0]: /home/hanseong/vscode/ML_code/FPL/FPL/src\n",
      "imports OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().resolve()   # Î≥¥ÌÜµ FPL Ìè¥ÎçîÏóêÏÑú ÎÖ∏Ìä∏Î∂Å Ïã§ÌñâÏ§ëÏù¥Î©¥ Ïù¥Í≤å Î£®Ìä∏\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ÌòÑÏû¨ ÎÖ∏Ìä∏Î∂ÅÏù¥ ÏûàÎäî Ìè¥Îçî(FPL) Í∏∞Ï§ÄÏúºÎ°ú src Ï†àÎåÄÍ≤ΩÎ°ú Í≥ÑÏÇ∞\n",
    "SRC_DIR = (Path(os.getcwd()) / \"src\").resolve()\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"SRC_DIR:\", SRC_DIR)\n",
    "print(\"SRC exists?:\", SRC_DIR.exists())\n",
    "\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.fpl_data_io import build_image_index, load_dataset\n",
    "from src.fpl_features import extract_color_hs_3x3, extract_hog_3x3\n",
    "from src.fpl_models import encode_road_labels, train_color_svm, train_hog_pca_svm_by_dims\n",
    "from src.fpl_fusion import fuse_probabilities\n",
    "from src.fpl_metrics import eval_accuracy, eval_confusion, eval_report\n",
    "from src.fpl_detail_models import train_and_save_detail_models\n",
    "from src.fpl_knn_models import train_and_save_knn_models\n",
    "\n",
    "from src.fpl_features import (\n",
    "    extract_color_hs_full,\n",
    "    extract_hog_full,\n",
    ")\n",
    "\n",
    "from src.fpl_models import (\n",
    "    encode_road_labels,\n",
    "    train_color_svm,\n",
    "    train_hog_pca_svm_by_dims,\n",
    "    eval_svm,\n",
    "    fit_sigmoid_calibrator,\n",
    "    predict_proba_custom,\n",
    "    fuse_probabilities,\n",
    "    evaluate_fusion,\n",
    ")\n",
    "\n",
    "print(\"imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a9f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "TRAINING_LABEL_CSV = \"/home/hanseong/gdrive/ML_FPL_training_data/training_labels_plus.csv\"\n",
    "TEST_LABEL_CSV  = \"/home/hanseong/gdrive/ML_FPL_test_data/test_labels_plus.csv\"\n",
    "\n",
    "test_path = \"/home/hanseong/gdrive/ML_FPL_test_data\"\n",
    "training_path = \"/home/hanseong/gdrive/ML_FPL_training_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8767a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed files: 2974\n",
      "sample: [('donhwamunro_11_da_A_raw_0824.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0824.jpg'), ('donhwamunro_11_da_A_raw_0825.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0825.jpg'), ('donhwamunro_11_da_A_raw_0826.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0826.jpg')]\n"
     ]
    }
   ],
   "source": [
    "# training/test Ìè¥Îçî Îëò Îã§ ÌõëÏñ¥ÏÑú filename -> fullpath Ïù∏Îç±Ïä§ ÏÉùÏÑ±\n",
    "image_index = build_image_index(training_path, test_path)\n",
    "\n",
    "print(\"indexed files:\", len(image_index))\n",
    "print(\"sample:\", list(image_index.items())[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ac674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images: 2231 missed: 0\n",
      "Loaded test  images: 743 missed: 0\n",
      "Train sample image shapes: {(682, 1024, 3)}\n",
      "Test  sample image shapes: {(682, 1024, 3)}\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(TRAINING_LABEL_CSV, image_index, resize=True)\n",
    "test  = load_dataset(TEST_LABEL_CSV, image_index, resize=True)\n",
    "\n",
    "Training_origin_data = train[\"images\"]\n",
    "Test_data = test[\"images\"]\n",
    "\n",
    "training_road_label = train[\"road_labels\"]\n",
    "test_road_label = test[\"road_labels\"]\n",
    "\n",
    "training_photo_id = train[\"photo_ids\"]\n",
    "test_photo_id = test[\"photo_ids\"]\n",
    "\n",
    "training_detail = train[\"details\"]\n",
    "test_detail = test[\"details\"]\n",
    "\n",
    "training_filename = train[\"filenames\"]\n",
    "test_filename = test[\"filenames\"]\n",
    "\n",
    "print(\"Loaded train images:\", len(Training_origin_data), \"missed:\", len(train[\"missed\"]))\n",
    "print(\"Loaded test  images:\", len(Test_data), \"missed:\", len(test[\"missed\"]))\n",
    "\n",
    "print(\"Train sample image shapes:\", {Training_origin_data[i].shape for i in range(min(5, len(Training_origin_data)))})\n",
    "print(\"Test  sample image shapes:\", {Test_data[i].shape for i in range(min(5, len(Test_data)))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bf032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = train[\"xs\"]; training_y = train[\"ys\"]\n",
    "test_x     = test[\"xs\"];  test_y     = test[\"ys\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e731d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num roads: 12\n",
      "y_train_road unique: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "y_test_road  unique: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "road_label_map sample: [('donhwamunro', 0), ('donhwamunro_11', 1), ('donhwamunro_11_da', 2), ('donhwamunro_11_ga', 3), ('donhwamunro_11_na', 4), ('samildaero', 5), ('samildaero_26', 6), ('samildaero_28', 7), ('samildaero_30', 8), ('samildaero_32', 9), ('samildaero_32_ga', 10), ('suporo_28', 11)]\n"
     ]
    }
   ],
   "source": [
    "y_train_road, y_test_road, road_label_map = encode_road_labels(training_road_label, test_road_label)\n",
    "\n",
    "print(\"num roads:\", len(road_label_map))\n",
    "print(\"y_train_road unique:\", np.unique(y_train_road))\n",
    "print(\"y_test_road  unique:\", np.unique(y_test_road))\n",
    "\n",
    "# Îß§Ìïë ÏùºÎ∂Ä ÌôïÏù∏\n",
    "items = list(road_label_map.items())\n",
    "print(\"road_label_map sample:\", items[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8ef2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All src modules reloaded and rebound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "\n",
    "# =========================\n",
    "# 1) Î™®Îìà import (as Î≥ÑÏπ≠)\n",
    "# =========================\n",
    "import src.fpl_data_io as fpl_data_io\n",
    "import src.fpl_features as fpl_features\n",
    "import src.fpl_models as fpl_models\n",
    "import src.fpl_fusion as fpl_fusion\n",
    "import src.fpl_metrics as fpl_metrics\n",
    "import src.fpl_detail_models as fpl_detail_models\n",
    "import src.fpl_knn_models as fpl_knn_models\n",
    "\n",
    "# =========================\n",
    "# 2) reload\n",
    "# =========================\n",
    "importlib.reload(fpl_data_io)\n",
    "importlib.reload(fpl_features)\n",
    "importlib.reload(fpl_models)\n",
    "importlib.reload(fpl_fusion)\n",
    "importlib.reload(fpl_metrics)\n",
    "importlib.reload(fpl_detail_models)\n",
    "importlib.reload(fpl_knn_models)\n",
    "\n",
    "# =========================\n",
    "# 3) Ìï®Ïàò Ïû¨Î∞îÏù∏Îî© (‚≠ê Ï§ëÏöî)\n",
    "# =========================\n",
    "# data io\n",
    "build_image_index = fpl_data_io.build_image_index\n",
    "load_dataset = fpl_data_io.load_dataset\n",
    "\n",
    "# features\n",
    "extract_color_hs_3x3 = fpl_features.extract_color_hs_3x3\n",
    "extract_hog_3x3      = fpl_features.extract_hog_3x3\n",
    "extract_color_hs_full = fpl_features.extract_color_hs_full\n",
    "extract_hog_full      = fpl_features.extract_hog_full\n",
    "\n",
    "# models\n",
    "encode_road_labels = fpl_models.encode_road_labels\n",
    "train_color_svm = fpl_models.train_color_svm\n",
    "train_hog_pca_svm_by_dims = fpl_models.train_hog_pca_svm_by_dims\n",
    "eval_svm = fpl_models.eval_svm\n",
    "fit_sigmoid_calibrator = fpl_models.fit_sigmoid_calibrator\n",
    "predict_proba_custom = fpl_models.predict_proba_custom\n",
    "\n",
    "# fusion\n",
    "fuse_probabilities = fpl_fusion.fuse_probabilities\n",
    "\n",
    "\n",
    "# metrics\n",
    "eval_accuracy = fpl_metrics.eval_accuracy\n",
    "eval_confusion = fpl_metrics.eval_confusion\n",
    "eval_report = fpl_metrics.eval_report\n",
    "\n",
    "# detail / knn\n",
    "train_and_save_detail_models = fpl_detail_models.train_and_save_detail_models\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n",
    "\n",
    "print(\"‚úÖ All src modules reloaded and rebound\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7268c8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hog_train: (2231, 97200)\n",
      "X_hog_test : (743, 97200)\n"
     ]
    }
   ],
   "source": [
    "# HOG\n",
    "X_hog_train = extract_hog_3x3(\n",
    "    Training_origin_data,\n",
    "    hog_size=(128, 128),\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2)\n",
    ")\n",
    "X_hog_test = extract_hog_3x3(\n",
    "    Test_data,\n",
    "    hog_size=(128, 128),\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2)\n",
    ")\n",
    "\n",
    "print(\"X_hog_train:\", X_hog_train.shape)\n",
    "print(\"X_hog_test :\", X_hog_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d45278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_color_train: (2231, 837)\n",
      "X_color_test : (743, 837)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Color (H,S)\n",
    "X_color_train = extract_color_hs_3x3(Training_origin_data, h_bins=45, s_bins=48)\n",
    "X_color_test  = extract_color_hs_3x3(Test_data, h_bins=45, s_bins=48)\n",
    "\n",
    "print(\"X_color_train:\", X_color_train.shape)\n",
    "print(\"X_color_test :\", X_color_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f04717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_color_test: (743, 12)\n",
      "Color SVM Test Accuracy: 0.721399730820996\n",
      "\n",
      "Color SVM Confusion Matrix:\n",
      " [[51  1  0  0  6  0  0  0  1  2  1  0]\n",
      " [ 6 34  0  0  1  0  0  0  0  0  1  1]\n",
      " [ 2  0 39  2  2  2  2  1  1  1  0  6]\n",
      " [ 4  0  0 47  9  3  0  0  1  3  3  2]\n",
      " [10  1  4 10 60  2  0  0  4  3  5  1]\n",
      " [ 5  2  2  0  1 49  0  0  0  2  3  2]\n",
      " [ 2  1  1  0  0  0 21  1  0  0  0  0]\n",
      " [ 4  2  1  1  0  1  0 26  0  1  0  2]\n",
      " [ 2  2  0  0  5  0  0  1 46  3  0  0]\n",
      " [ 7  0  0  1  5  3  0  2  0 61  0  0]\n",
      " [ 5  0  0  0  5  2  0  0  1  3 27  0]\n",
      " [11  1  1  3  2  1  3  0  0  0  0 75]]\n",
      "\n",
      "Color SVM Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4679    0.8226    0.5965        62\n",
      "           1     0.7727    0.7907    0.7816        43\n",
      "           2     0.8125    0.6724    0.7358        58\n",
      "           3     0.7344    0.6528    0.6912        72\n",
      "           4     0.6250    0.6000    0.6122       100\n",
      "           5     0.7778    0.7424    0.7597        66\n",
      "           6     0.8077    0.8077    0.8077        26\n",
      "           7     0.8387    0.6842    0.7536        38\n",
      "           8     0.8519    0.7797    0.8142        59\n",
      "           9     0.7722    0.7722    0.7722        79\n",
      "          10     0.6750    0.6279    0.6506        43\n",
      "          11     0.8427    0.7732    0.8065        97\n",
      "\n",
      "    accuracy                         0.7214       743\n",
      "   macro avg     0.7482    0.7271    0.7318       743\n",
      "weighted avg     0.7415    0.7214    0.7258       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.fpl_models import train_color_svm, train_hog_pca_svm_by_dims\n",
    "from src.fpl_models import fit_sigmoid_calibrator, predict_proba_custom \n",
    "color_svm = train_color_svm(X_color_train, y_train_road, C=10, gamma=\"scale\")\n",
    "\n",
    "cal_color = fit_sigmoid_calibrator(color_svm, X_color_train, y_train_road,\n",
    "                                  q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95) \n",
    "P_color_train = predict_proba_custom(color_svm, X_color_train,\n",
    "                                    method=\"sigmoid\", calibrator=cal_color, power=1.0)\n",
    "P_color_test = predict_proba_custom(color_svm, X_color_test,\n",
    "                                   method=\"sigmoid\", calibrator=cal_color, power=1.0)  \n",
    "\n",
    "\n",
    "print(\"P_color_test:\", P_color_test.shape)\n",
    "\n",
    "# 1) test ÏòàÏ∏° ÎùºÎ≤® (ÌôïÎ•†Ïù¥ Í∞ÄÏû• ÌÅ∞ ÌÅ¥ÎûòÏä§)\n",
    "y_pred_color = np.argmax(P_color_test, axis=1)\n",
    "\n",
    "# 2) Ï†ïÌôïÎèÑ\n",
    "acc_color = eval_accuracy(y_test_road, y_pred_color)\n",
    "print(\"Color SVM Test Accuracy:\", acc_color)\n",
    "\n",
    "# 3) confusion matrix + report\n",
    "cm_color = eval_confusion(y_test_road, y_pred_color)\n",
    "print(\"\\nColor SVM Confusion Matrix:\\n\", cm_color)\n",
    "\n",
    "print(\"\\nColor SVM Classification Report:\\n\")\n",
    "print(eval_report(y_test_road, y_pred_color))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ebb411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HOG+PCA SVM summary =====\n",
      "PCA   2 | Test Acc=0.2180 | scale=2.613s pca=1.402s svm=0.215s total=4.413s\n",
      "PCA   8 | Test Acc=0.3526 | scale=2.691s pca=1.114s svm=0.153s total=4.139s\n",
      "PCA  16 | Test Acc=0.5114 | scale=2.506s pca=1.164s svm=0.186s total=4.042s\n",
      "PCA  32 | Test Acc=0.5424 | scale=2.284s pca=1.452s svm=0.195s total=4.133s\n",
      "PCA  64 | Test Acc=0.5262 | scale=2.227s pca=2.116s svm=0.218s total=4.801s\n",
      "PCA 128 | Test Acc=0.4899 | scale=2.325s pca=3.504s svm=0.247s total=6.424s\n",
      "PCA 256 | Test Acc=0.4455 | scale=2.132s pca=3.950s svm=0.356s total=7.024s\n"
     ]
    }
   ],
   "source": [
    "PCA_DIMS = [2, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "hog_pack = train_hog_pca_svm_by_dims(\n",
    "    X_train=X_hog_train,\n",
    "    y_train=y_train_road,\n",
    "    X_test=X_hog_test,\n",
    "    y_test=y_test_road,\n",
    "    pca_dims=PCA_DIMS,\n",
    "    C=10,\n",
    "    gamma=\"scale\"\n",
    ")\n",
    "\n",
    "# ‚úÖ 1) Î®ºÏ†Ä Í∫ºÎÇ¥Í∏∞\n",
    "hog_svm_models = hog_pack[\"hog_svm_models\"]\n",
    "hog_pca_train_features = hog_pack[\"hog_pca_train_features\"]\n",
    "hog_pca_test_features  = hog_pack[\"hog_pca_test_features\"]\n",
    "hog_test_acc = hog_pack[\"test_acc\"]\n",
    "hog_time_report = hog_pack[\"time_report\"]\n",
    "\n",
    "# ‚úÖ 2) calibrator ÏÉùÏÑ±\n",
    "cal_hog_by_dim = {}\n",
    "for d in PCA_DIMS:\n",
    "    cal_hog_by_dim[d] = fit_sigmoid_calibrator(\n",
    "        hog_svm_models[d],\n",
    "        hog_pca_train_features[d],\n",
    "        y_train_road,\n",
    "        q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95\n",
    "    )\n",
    "\n",
    "print(\"\\n===== HOG+PCA SVM summary =====\")\n",
    "for d in PCA_DIMS:\n",
    "    tr = hog_time_report[d]\n",
    "    print(\n",
    "        f\"PCA {d:>3d} | \"\n",
    "        f\"Test Acc={hog_test_acc[d]:.4f} | \"\n",
    "        f\"scale={tr['scale_sec']:.3f}s pca={tr['pca_sec']:.3f}s svm={tr['svm_fit_sec']:.3f}s total={tr['total_sec']:.3f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c29ac",
   "metadata": {},
   "source": [
    "ALPHA Line regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b343bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LR Fusion per PCA dim =====\n",
      "[PCA dim=  2] alpha_hat(shape)=0.338 | TestAcc=0.7308 | P_fusion_test=(743, 12)\n",
      "[PCA dim=  8] alpha_hat(shape)=0.399 | TestAcc=0.7322 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 16] alpha_hat(shape)=0.401 | TestAcc=0.7308 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 32] alpha_hat(shape)=0.418 | TestAcc=0.7429 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 64] alpha_hat(shape)=0.412 | TestAcc=0.7429 | P_fusion_test=(743, 12)\n",
      "[PCA dim=128] alpha_hat(shape)=0.389 | TestAcc=0.7497 | P_fusion_test=(743, 12)\n",
      "[PCA dim=256] alpha_hat(shape)=0.357 | TestAcc=0.7362 | P_fusion_test=(743, 12)\n",
      "\n",
      "===== Summary =====\n",
      "dim=  2 | alpha_hat=0.338 | acc=0.7308 | P_fusion=(743, 12)\n",
      "dim=  8 | alpha_hat=0.399 | acc=0.7322 | P_fusion=(743, 12)\n",
      "dim= 16 | alpha_hat=0.401 | acc=0.7308 | P_fusion=(743, 12)\n",
      "dim= 32 | alpha_hat=0.418 | acc=0.7429 | P_fusion=(743, 12)\n",
      "dim= 64 | alpha_hat=0.412 | acc=0.7429 | P_fusion=(743, 12)\n",
      "dim=128 | alpha_hat=0.389 | acc=0.7497 | P_fusion=(743, 12)\n",
      "dim=256 | alpha_hat=0.357 | acc=0.7362 | P_fusion=(743, 12)\n",
      "row-sum check: 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =========================\n",
    "# ÏûÖÎ†• Ï†ÑÏ†ú(Ïù¥ÎØ∏ ÏûàÏñ¥Ïïº Ìï®)\n",
    "# =========================\n",
    "# PCA_DIMS: list[int]\n",
    "# hog_svm_models: dict[dim -> SVC(probability=True)]\n",
    "# hog_pca_test_features: dict[dim -> np.ndarray (N_test, dim)]\n",
    "# P_color_test: np.ndarray (N_test, K)\n",
    "# y_test_road: np.ndarray (N_test,)\n",
    "# eval_accuracy: Ìï®Ïàò(ÏóÜÏúºÎ©¥ accuracy_scoreÎ°ú ÎåÄÏ≤¥ Í∞ÄÎä•)\n",
    "\n",
    "fusion_lr_models = {}      # dim -> LogisticRegression\n",
    "fusion_alpha = {}          # dim -> float (shape vs color ÏöîÏïΩ alpha)\n",
    "P_fusion_by_dim = {}       # dim -> np.ndarray (N_test, K)\n",
    "fusion_acc = {}            # dim -> float\n",
    "\n",
    "K = P_color_test.shape[1]\n",
    "\n",
    "print(\"===== LR Fusion per PCA dim =====\")\n",
    "\n",
    "for d in PCA_DIMS:\n",
    "    # 1) HOG ÌôïÎ•† (N_test, K)\n",
    "    P_shape_test = predict_proba_custom(\n",
    "    hog_svm_models[d],\n",
    "    hog_pca_test_features[d],\n",
    "    method=\"sigmoid\",\n",
    "    calibrator=cal_hog_by_dim[d],\n",
    "    power=1.0\n",
    "    )\n",
    "    # shape Ï≤¥ÌÅ¨\n",
    "    assert P_shape_test.shape == P_color_test.shape, (\n",
    "        f\"[dim={d}] P_shape_test {P_shape_test.shape} vs P_color_test {P_color_test.shape} mismatch\"\n",
    "    )\n",
    "\n",
    "    # 2) fusion ÏûÖÎ†• (N_test, 2K)\n",
    "    X_fuse = np.hstack([P_shape_test, P_color_test])\n",
    "\n",
    "    # 3) ÌöåÍ∑Ä(Î°úÏßÄÏä§Ìã±)Î°ú fusion ÌïôÏäµ (ÏöîÍµ¨ÎåÄÎ°ú test ÎùºÎ≤® ÏÇ¨Ïö©)\n",
    "    lr = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000\n",
    "    )\n",
    "\n",
    "    lr.fit(X_fuse, y_test_road)\n",
    "\n",
    "    # 4) fusion ÌôïÎ•† Ï∂úÎ†• (N_test, K)\n",
    "    P_fusion_test = lr.predict_proba(X_fuse)\n",
    "\n",
    "    # 5) Ï†ïÌôïÎèÑ(Ï∞∏Í≥†)\n",
    "    y_pred = np.argmax(P_fusion_test, axis=1).astype(np.int64)\n",
    "    acc = eval_accuracy(y_test_road, y_pred)\n",
    "\n",
    "    # 6) \"alpha(ÌòïÌÉú ÎπÑÏ§ë)\" ÏöîÏïΩÍ∞í Í≥ÑÏÇ∞\n",
    "    # lr.coef_ shape: (K, 2K)\n",
    "    W = lr.coef_\n",
    "    w_shape = np.mean(np.abs(W[:, :K]))\n",
    "    w_color = np.mean(np.abs(W[:, K:]))\n",
    "\n",
    "    alpha_hat = float(w_shape / (w_shape + w_color + 1e-12))  # 0~1, ÌòïÌÉú ÏòÅÌñ• ÎπÑÏ§ë\n",
    "\n",
    "    # Ï†ÄÏû•\n",
    "    fusion_lr_models[d] = lr\n",
    "    fusion_alpha[d] = alpha_hat\n",
    "    P_fusion_by_dim[d] = P_fusion_test\n",
    "    fusion_acc[d] = float(acc)\n",
    "\n",
    "    # Ï∂úÎ†•\n",
    "    print(f\"[PCA dim={d:>3d}] alpha_hat(shape)={alpha_hat:.3f} | TestAcc={acc:.4f} | P_fusion_test={P_fusion_test.shape}\")\n",
    "\n",
    "# dimÎ≥Ñ ÏöîÏïΩ\n",
    "print(\"\\n===== Summary =====\")\n",
    "for d in PCA_DIMS:\n",
    "    print(f\"dim={d:>3d} | alpha_hat={fusion_alpha[d]:.3f} | acc={fusion_acc[d]:.4f} | P_fusion={P_fusion_by_dim[d].shape}\")\n",
    "\n",
    "print(\"row-sum check:\", P_color_test[0].sum(), P_shape_test[0].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a17cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (LR-Fusion, PCA=128):\n",
      " [[49  1  0  0  7  1  0  0  1  2  1  0]\n",
      " [ 2 34  0  0  3  0  0  0  0  1  1  2]\n",
      " [ 1  0 39  2  2  2  0  1  1  1  0  9]\n",
      " [ 1  0  0 54  7  3  0  0  1  1  3  2]\n",
      " [ 1  1  5 11 65  2  0  0  4  4  5  2]\n",
      " [ 1  2  2  0  2 49  0  0  0  4  3  3]\n",
      " [ 0  1  1  2  0  0 20  1  0  0  0  1]\n",
      " [ 1  2  1  1  0  1  1 27  0  1  0  3]\n",
      " [ 0  2  0  0  6  0  0  1 47  3  0  0]\n",
      " [ 1  0  0  1  7  3  0  2  1 63  0  1]\n",
      " [ 1  0  0  0  7  2  0  1  1  3 27  1]\n",
      " [ 1  1  1  3  6  1  1  0  0  0  0 83]]\n",
      "\n",
      "Classification Report (LR-Fusion, PCA=128):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8305    0.7903    0.8099        62\n",
      "           1     0.7727    0.7907    0.7816        43\n",
      "           2     0.7959    0.6724    0.7290        58\n",
      "           3     0.7297    0.7500    0.7397        72\n",
      "           4     0.5804    0.6500    0.6132       100\n",
      "           5     0.7656    0.7424    0.7538        66\n",
      "           6     0.9091    0.7692    0.8333        26\n",
      "           7     0.8182    0.7105    0.7606        38\n",
      "           8     0.8393    0.7966    0.8174        59\n",
      "           9     0.7590    0.7975    0.7778        79\n",
      "          10     0.6750    0.6279    0.6506        43\n",
      "          11     0.7757    0.8557    0.8137        97\n",
      "\n",
      "    accuracy                         0.7497       743\n",
      "   macro avg     0.7709    0.7461    0.7567       743\n",
      "weighted avg     0.7543    0.7497    0.7505       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_dim = max(fusion_acc, key=fusion_acc.get)\n",
    "\n",
    "y_pred_best = np.argmax(P_fusion_by_dim[best_dim], axis=1)\n",
    "\n",
    "cm = eval_confusion(y_test_road, y_pred_best)\n",
    "print(f\"Confusion Matrix (LR-Fusion, PCA={best_dim}):\\n\", cm)\n",
    "\n",
    "print(f\"\\nClassification Report (LR-Fusion, PCA={best_dim}):\\n\")\n",
    "print(eval_report(y_test_road, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ada0e",
   "metadata": {},
   "source": [
    "models save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9908ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved with best_dim = 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# best_dim Í∏∞Ï§Ä Î™®Îç∏ ÏÑ†ÌÉù\n",
    "# =========================\n",
    "best_dim = best_dim   # Ïù¥ÎØ∏ ÏúÑÏóêÏÑú Í≥ÑÏÇ∞Îêú Í∞í ÏÇ¨Ïö©\n",
    "\n",
    "hog_scaler = hog_pack[\"hog_pca_models\"][best_dim][0]\n",
    "hog_pca    = hog_pack[\"hog_pca_models\"][best_dim][1]\n",
    "hog_svm    = hog_pack[\"hog_svm_models\"][best_dim]\n",
    "\n",
    "# LR-fusion Î™®Îç∏ (ÏûàÎã§Î©¥)\n",
    "best_fusion_lr = fusion_lr_models[best_dim]\n",
    "hog_cal = cal_hog_by_dim[best_dim]\n",
    "color_cal = cal_color \n",
    "# =========================\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "# =========================\n",
    "joblib.dump(hog_svm,        f\"{MODEL_DIR}/hog_svm_dim{best_dim}.pkl\")\n",
    "joblib.dump(hog_pca,        f\"{MODEL_DIR}/hog_pca_dim{best_dim}.pkl\")\n",
    "joblib.dump(hog_scaler,     f\"{MODEL_DIR}/hog_scaler_dim{best_dim}.pkl\")\n",
    "joblib.dump(hog_cal,    f\"{MODEL_DIR}/hog_cal_dim{best_dim}.pkl\")\n",
    "joblib.dump(color_cal, f\"{MODEL_DIR}/color_cal.pkl\")\n",
    "joblib.dump(color_svm,      f\"{MODEL_DIR}/color_svm.pkl\")\n",
    "joblib.dump(best_fusion_lr, f\"{MODEL_DIR}/fusion_lr_dim{best_dim}.pkl\")\n",
    "\n",
    "joblib.dump(road_label_map, f\"{MODEL_DIR}/road_label_map.pkl\")\n",
    "\n",
    "print(\"Models saved with best_dim =\", best_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05036adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_knn_models.py\n",
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_detail_models.py\n",
      "new signature: (X_hog_train, X_color_train, training_road_label, training_detail, training_x, training_y, out_dir, hog_pca_dim=128, n_neighbors=7, detail_roads={'suporo_28', 'donhwamunro_11_ga', 'donhwamunro_11_na', 'donhwamunro_11_da'}, min_samples=10, training_paths=None, feature_tag='full')\n"
     ]
    }
   ],
   "source": [
    "import importlib, inspect\n",
    "import fpl_knn_models\n",
    "import fpl_detail_models\n",
    "\n",
    "print(\"loaded from:\", fpl_knn_models.__file__)\n",
    "importlib.reload(fpl_knn_models)\n",
    "print(\"loaded from:\", fpl_detail_models.__file__)\n",
    "importlib.reload(fpl_detail_models)\n",
    "\n",
    "print(\"new signature:\", inspect.signature(fpl_knn_models.train_and_save_knn_models))\n",
    "\n",
    "# ‚úÖ Ïù¥ Ï§ÑÏù¥ Ï§ëÏöî: Î°úÏª¨ Ïù¥Î¶ÑÏùÑ 'ÏÉà Ìï®Ïàò'Î°ú Îã§Ïãú Î∞îÏù∏Îî©\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "457b13cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] detail(patch3x3) road=donhwamunro_11_da | classes=['A', 'B', 'C'] | n=177 | pca=128\n",
      "[SAVED] detail(patch3x3) road=donhwamunro_11_ga | classes=['A', 'B', 'C'] | n=213 | pca=128\n",
      "[SAVED] detail(patch3x3) road=donhwamunro_11_na | classes=['A', 'B', 'C', 'D'] | n=300 | pca=128\n",
      "[SAVED] detail(patch3x3) road=suporo_28 | classes=['A', 'B', 'C', 'D', 'E'] | n=296 | pca=128\n",
      "[SAVED] KNN(patch3x3) road=donhwamunro | n=189\n",
      "[SAVED] KNN(patch3x3) road=donhwamunro_11 | n=130\n",
      "[SAVED] KNN(patch3x3) road=donhwamunro_11_da | n=177\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_da detail=A | n=90\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_da detail=B | n=49\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_da detail=C | n=38\n",
      "[SAVED] KNN(patch3x3) road=donhwamunro_11_ga | n=213\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_ga detail=A | n=46\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_ga detail=B | n=79\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_ga detail=C | n=88\n",
      "[SAVED] KNN(patch3x3) road=donhwamunro_11_na | n=300\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_na detail=A | n=67\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_na detail=B | n=126\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_na detail=C | n=55\n",
      "  [SAVED] KNN(patch3x3) road=donhwamunro_11_na detail=D | n=52\n",
      "[SAVED] KNN(patch3x3) road=samildaero | n=199\n",
      "[SAVED] KNN(patch3x3) road=samildaero_26 | n=79\n",
      "[SAVED] KNN(patch3x3) road=samildaero_28 | n=114\n",
      "[SAVED] KNN(patch3x3) road=samildaero_30 | n=176\n",
      "[SAVED] KNN(patch3x3) road=samildaero_32 | n=229\n",
      "[SAVED] KNN(patch3x3) road=samildaero_32_ga | n=129\n",
      "[SAVED] KNN(patch3x3) road=suporo_28 | n=296\n",
      "  [SAVED] KNN(patch3x3) road=suporo_28 detail=A | n=104\n",
      "  [SAVED] KNN(patch3x3) road=suporo_28 detail=B | n=60\n",
      "  [SAVED] KNN(patch3x3) road=suporo_28 detail=C | n=38\n",
      "  [SAVED] KNN(patch3x3) road=suporo_28 detail=D | n=61\n",
      "  [SAVED] KNN(patch3x3) road=suporo_28 detail=E | n=33\n",
      "‚úÖ KNN saved under: FPL_models/knn_models_patch3x3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'saved': [('donhwamunro', 'road'),\n",
       "  ('donhwamunro_11', 'road'),\n",
       "  ('donhwamunro_11_da', 'road'),\n",
       "  ('donhwamunro_11_da', 'A'),\n",
       "  ('donhwamunro_11_da', 'B'),\n",
       "  ('donhwamunro_11_da', 'C'),\n",
       "  ('donhwamunro_11_ga', 'road'),\n",
       "  ('donhwamunro_11_ga', 'A'),\n",
       "  ('donhwamunro_11_ga', 'B'),\n",
       "  ('donhwamunro_11_ga', 'C'),\n",
       "  ('donhwamunro_11_na', 'road'),\n",
       "  ('donhwamunro_11_na', 'A'),\n",
       "  ('donhwamunro_11_na', 'B'),\n",
       "  ('donhwamunro_11_na', 'C'),\n",
       "  ('donhwamunro_11_na', 'D'),\n",
       "  ('samildaero', 'road'),\n",
       "  ('samildaero_26', 'road'),\n",
       "  ('samildaero_28', 'road'),\n",
       "  ('samildaero_30', 'road'),\n",
       "  ('samildaero_32', 'road'),\n",
       "  ('samildaero_32_ga', 'road'),\n",
       "  ('suporo_28', 'road'),\n",
       "  ('suporo_28', 'A'),\n",
       "  ('suporo_28', 'B'),\n",
       "  ('suporo_28', 'C'),\n",
       "  ('suporo_28', 'D'),\n",
       "  ('suporo_28', 'E')],\n",
       " 'knn_root': 'FPL_models/knn_models_patch3x3',\n",
       " 'pca_dim_actual': 128,\n",
       " 'feature_tag': 'patch3x3'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = \"FPL_models\"  \n",
    "ALPHA_FIXED = float(fusion_alpha[best_dim])   # Î™®Îì† ÎîîÌÖåÏùº ÎèÑÎ°úÏóê ÎèôÏùº Ï†ÅÏö©\n",
    "PCA_DIM_DETAIL = best_dim                     # ÎîîÌÖåÏùº HOG PCAÎèÑ ÎèôÏùº dim ÏÇ¨Ïö©(ÏõêÌïòÎ©¥ Ïà´Ïûê Í≥†Ï†ïÌï¥ÎèÑ Îê®)\n",
    "\n",
    "training_paths = np.array([image_index.get(fn, \"\") for fn in training_filename], dtype=object)\n",
    "# 1) detail ÎèÑÎ°úÎì§Ïóê ÎåÄÌï¥ detail Î∂ÑÎ•òÏö© (Color SVM + HOG SVM) Ï†ÄÏû•\n",
    "detail_pack = train_and_save_detail_models(\n",
    "    X_hog_train=X_hog_train,\n",
    "    X_color_train=X_color_train,\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "\n",
    "    out_dir=MODEL_DIR,                \n",
    "    alpha_shape=ALPHA_FIXED,          \n",
    "    hog_pca_dim=PCA_DIM_DETAIL,       \n",
    "\n",
    "    C=10,\n",
    "    gamma=\"scale\",\n",
    "\n",
    "    min_total_samples=20,             \n",
    "    min_samples_per_detail=8,\n",
    "    feature_tag=\"patch3x3\"          \n",
    ")\n",
    "\n",
    "detail_pack\n",
    "\n",
    "\n",
    "# 2) Î™®Îì† ÎèÑÎ°úÎ™ÖÏóê ÎåÄÌï¥ KNN(ÏúÑÏπò ÌöåÍ∑Ä) Ï†ÄÏû• + detail ÎèÑÎ°úÎäî A/B/...Î≥Ñ KNN Ï∂îÍ∞Ä Ï†ÄÏû•\n",
    "train_and_save_knn_models(\n",
    "    X_hog_train=X_hog_train,\n",
    "    X_color_train=X_color_train,\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    training_x=training_x,\n",
    "    training_y=training_y,\n",
    "    out_dir=MODEL_DIR,\n",
    "    hog_pca_dim=best_dim,\n",
    "    n_neighbors=7,\n",
    "    min_samples=10,\n",
    "    training_paths=training_paths,\n",
    "    feature_tag=\"patch3x3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e1ff0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ loaded: knn_hog_scaler_pca128.pkl knn_hog_pca_pca128.pkl\n",
      "Z_test shape: (743, 965)\n",
      "\n",
      "‚úÖ [KNN XY] Overall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_eval</th>\n",
       "      <th>mae_x</th>\n",
       "      <th>rmse_x</th>\n",
       "      <th>mae_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>mae_dist</th>\n",
       "      <th>rmse_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743</td>\n",
       "      <td>0.466545</td>\n",
       "      <td>0.778131</td>\n",
       "      <td>0.484507</td>\n",
       "      <td>0.896316</td>\n",
       "      <td>0.788465</td>\n",
       "      <td>1.186959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_eval     mae_x    rmse_x     mae_y    rmse_y  mae_dist  rmse_dist\n",
       "0     743  0.466545  0.778131  0.484507  0.896316  0.788465   1.186959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Road-wise error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road</th>\n",
       "      <th>mae_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>samildaero</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>samildaero_32</td>\n",
       "      <td>5.761906e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>samildaero_26</td>\n",
       "      <td>1.995845e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>samildaero_28</td>\n",
       "      <td>4.119368e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>samildaero_32_ga</td>\n",
       "      <td>5.337569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donhwamunro_11_da</td>\n",
       "      <td>8.596453e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donhwamunro_11</td>\n",
       "      <td>8.805383e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donhwamunro</td>\n",
       "      <td>9.174261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>suporo_28</td>\n",
       "      <td>1.055655e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>samildaero_30</td>\n",
       "      <td>1.135010e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donhwamunro_11_ga</td>\n",
       "      <td>1.298641e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>donhwamunro_11_na</td>\n",
       "      <td>1.345656e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 road      mae_dist\n",
       "5          samildaero  0.000000e+00\n",
       "9       samildaero_32  5.761906e-16\n",
       "6       samildaero_26  1.995845e-01\n",
       "7       samildaero_28  4.119368e-01\n",
       "10   samildaero_32_ga  5.337569e-01\n",
       "2   donhwamunro_11_da  8.596453e-01\n",
       "1      donhwamunro_11  8.805383e-01\n",
       "0         donhwamunro  9.174261e-01\n",
       "11          suporo_28  1.055655e+00\n",
       "8       samildaero_30  1.135010e+00\n",
       "3   donhwamunro_11_ga  1.298641e+00\n",
       "4   donhwamunro_11_na  1.345656e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# KNN Evaluation (CORRECT version)\n",
    "# =========================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "KNN_ROOT = os.path.join(MODEL_DIR, \"knn_models_patch3x3\")\n",
    "\n",
    "# -------------------------\n",
    "# ÌïÑÏàò Î≥ÄÏàò Ï≤¥ÌÅ¨\n",
    "# -------------------------\n",
    "need = [\n",
    "    \"X_hog_test\", \"X_color_test\",\n",
    "    \"y_test_road_label\", \"y_test_detail\",\n",
    "    \"test_x\", \"test_y\"\n",
    "]\n",
    "missing = [v for v in need if v not in globals()]\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùó ÌïÑÏöîÌïú Î≥ÄÏàòÍ∞Ä ÏóÜÏäµÎãàÎã§: {missing}\")\n",
    "\n",
    "def _clean_detail(d):\n",
    "    if d is None:\n",
    "        return \"0\"\n",
    "    s = str(d).strip()\n",
    "    if s.lower() in (\"nan\", \"none\", \"\"):\n",
    "        return \"0\"\n",
    "    return s\n",
    "\n",
    "def _mae_rmse(pred, true):\n",
    "    pred = np.asarray(pred, dtype=float)\n",
    "    true = np.asarray(true, dtype=float)\n",
    "    diff = pred - true\n",
    "    return float(np.mean(np.abs(diff))), float(np.sqrt(np.mean(diff**2)))\n",
    "\n",
    "# -------------------------\n",
    "# 1) Í≥µÌÜµ HOG scaler / PCA Î°úÎìú\n",
    "# -------------------------\n",
    "scaler_path = [p for p in os.listdir(KNN_ROOT) if p.startswith(\"knn_hog_scaler\")][0]\n",
    "pca_path    = [p for p in os.listdir(KNN_ROOT) if p.startswith(\"knn_hog_pca\")][0]\n",
    "\n",
    "hog_scaler = joblib.load(os.path.join(KNN_ROOT, scaler_path))\n",
    "hog_pca    = joblib.load(os.path.join(KNN_ROOT, pca_path))\n",
    "\n",
    "print(\"‚úÖ loaded:\", scaler_path, pca_path)\n",
    "\n",
    "# -------------------------\n",
    "# 2) test feature Î≥ÄÌôò (üî• ÌïµÏã¨)\n",
    "# -------------------------\n",
    "Xh_test_p = hog_pca.transform(hog_scaler.transform(X_hog_test))\n",
    "Z_test = np.hstack([Xh_test_p, X_color_test])\n",
    "\n",
    "print(\"Z_test shape:\", Z_test.shape)\n",
    "\n",
    "# -------------------------\n",
    "# 3) ÏòàÏ∏°\n",
    "# -------------------------\n",
    "N = len(Z_test)\n",
    "pred_x = np.full(N, np.nan)\n",
    "pred_y = np.full(N, np.nan)\n",
    "missing_models = defaultdict(int)\n",
    "\n",
    "y_test_road_label = np.asarray(y_test_road_label, dtype=object)\n",
    "y_test_detail     = np.asarray([_clean_detail(d) for d in y_test_detail], dtype=object)\n",
    "\n",
    "for i in range(N):\n",
    "    road = str(y_test_road_label[i])\n",
    "    det  = str(y_test_detail[i])\n",
    "\n",
    "    # detail Ïö∞ÏÑ† ‚Üí road fallback\n",
    "    cand = []\n",
    "    if det != \"0\":\n",
    "        cand.append(os.path.join(KNN_ROOT, road, f\"knn_detail_{det}.pkl\"))\n",
    "    cand.append(os.path.join(KNN_ROOT, road, \"knn_road.pkl\"))\n",
    "\n",
    "    model_path = None\n",
    "    for p in cand:\n",
    "        if os.path.exists(p):\n",
    "            model_path = p\n",
    "            break\n",
    "\n",
    "    if model_path is None:\n",
    "        missing_models[(road, det)] += 1\n",
    "        continue\n",
    "\n",
    "    knn = joblib.load(model_path)\n",
    "    xy_hat = knn.predict(Z_test[i].reshape(1, -1)).ravel()\n",
    "    pred_x[i], pred_y[i] = xy_hat\n",
    "\n",
    "# -------------------------\n",
    "# 4) ÌèâÍ∞Ä\n",
    "# -------------------------\n",
    "test_x = np.asarray(test_x, dtype=float)\n",
    "test_y = np.asarray(test_y, dtype=float)\n",
    "\n",
    "valid = np.isfinite(pred_x) & np.isfinite(pred_y)\n",
    "idx = np.where(valid)[0]\n",
    "\n",
    "if len(idx) == 0:\n",
    "    print(\"‚ùó ÏòàÏ∏° ÏÑ±Í≥µ ÏÉòÌîå ÏóÜÏùå\")\n",
    "    print(\"missing models:\", dict(missing_models))\n",
    "else:\n",
    "    mae_x, rmse_x = _mae_rmse(pred_x[idx], test_x[idx])\n",
    "    mae_y, rmse_y = _mae_rmse(pred_y[idx], test_y[idx])\n",
    "\n",
    "    dist = np.sqrt((pred_x[idx] - test_x[idx])**2 + (pred_y[idx] - test_y[idx])**2)\n",
    "    mae_dist  = float(np.mean(dist))\n",
    "    rmse_dist = float(np.sqrt(np.mean(dist**2)))\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"n_eval\": len(idx),\n",
    "        \"mae_x\": mae_x,\n",
    "        \"rmse_x\": rmse_x,\n",
    "        \"mae_y\": mae_y,\n",
    "        \"rmse_y\": rmse_y,\n",
    "        \"mae_dist\": mae_dist,\n",
    "        \"rmse_dist\": rmse_dist,\n",
    "    }])\n",
    "\n",
    "    print(\"\\n‚úÖ [KNN XY] Overall\")\n",
    "    display(df)\n",
    "\n",
    "    # ÎèÑÎ°úÎ≥Ñ\n",
    "    road_err = {}\n",
    "    for r in np.unique(y_test_road_label[idx]):\n",
    "        j = idx[y_test_road_label[idx] == r]\n",
    "        road_err[str(r)] = float(np.mean(\n",
    "            np.sqrt((pred_x[j] - test_x[j])**2 + (pred_y[j] - test_y[j])**2)\n",
    "        ))\n",
    "\n",
    "    df_road = pd.DataFrame([\n",
    "        {\"road\": k, \"mae_dist\": v} for k, v in road_err.items()\n",
    "    ]).sort_values(\"mae_dist\")\n",
    "\n",
    "    print(\"\\n‚úÖ Road-wise error\")\n",
    "    display(df_road)\n",
    "\n",
    "    if missing_models:\n",
    "        print(\"\\n‚ö†Ô∏è Missing models (top-10):\")\n",
    "        for (road, det), cnt in sorted(missing_models.items(), key=lambda x: -x[1])[:10]:\n",
    "            print(f\"  road={road}, detail={det} ‚Üí {cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4d5fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: 20964.5 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil, os\n",
    "print(f\"RAM: {psutil.Process(os.getpid()).memory_info().rss / 1024**2:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8d66346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 3x3 variables cleaned. Ready for FULL feature extraction.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3x3 feature / model cleanup\n",
    "# =========================\n",
    "import gc\n",
    "\n",
    "# ---- HOG / Color feature ----\n",
    "for var in [\n",
    "    \"X_hog_train\", \"X_hog_test\",\n",
    "    \"X_color_train\", \"X_color_test\",\n",
    "]:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# ---- HOG PCA / SVM packs ----\n",
    "for var in [\n",
    "    \"hog_pack\",\n",
    "    \"hog_svm_models\",\n",
    "    \"hog_pca_test_features\",\n",
    "    \"hog_pca_train_features\",\n",
    "    \"hog_test_acc\",\n",
    "    \"hog_time_report\",\n",
    "]:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# ---- Fusion Í¥ÄÎ†® ----\n",
    "for var in [\n",
    "    \"P_color_test\",\n",
    "    \"P_shape_test\",\n",
    "    \"P_fusion_by_dim\",\n",
    "    \"fusion_lr_models\",\n",
    "    \"fusion_alpha\",\n",
    "    \"fusion_acc\",\n",
    "]:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# ---- Calibrators ----\n",
    "for var in [\n",
    "    \"cal_color\",\n",
    "    \"cal_hog_by_dim\",\n",
    "]:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# ---- ÏûÑÏãú Í≤∞Í≥º ----\n",
    "for var in [\n",
    "    \"y_pred_color\",\n",
    "    \"y_pred_best\",\n",
    "    \"cm\",\n",
    "]:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# ---- Python GC ----\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ 3x3 variables cleaned. Ready for FULL feature extraction.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b321b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 19467.1 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil, os\n",
    "print(f\"RAM used: {psutil.Process(os.getpid()).memory_info().rss / 1024**2:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb94a49",
   "metadata": {},
   "source": [
    "not 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "779532e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_color_train: (2231, 124) float32\n",
      "X_hog_train  : (2231, 22320) float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.fpl_models import fit_sigmoid_calibrator, predict_proba_custom\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) (Ïù¥ÎØ∏ Ï§ÄÎπÑÎêòÏñ¥ ÏûàÎã§Í≥† Í∞ÄÏ†ï)\n",
    "# - Training_origin_data, Test_data\n",
    "# - y_train_road, y_test_road\n",
    "# - road_label_map  (ÏûàÏúºÎ©¥ Ï†ÄÏû•Ïö©)\n",
    "# =========================\n",
    "\n",
    "# =========================\n",
    "# 1) Feature Extraction (FULL)\n",
    "# =========================\n",
    "# Color (HS hist) - full image (Ï∞®Ïõê Í≥†Ï†ïÏù¥Îùº ÏïàÏ†Ñ)\n",
    "X_color_train = extract_color_hs_full(\n",
    "    Training_origin_data, h_bins=60, s_bins=64, sizes=None\n",
    ")\n",
    "X_color_test  = extract_color_hs_full(\n",
    "    Test_data,            h_bins=60, s_bins=64, sizes=None\n",
    ")\n",
    "\n",
    "# HOG - full image (Î∞òÎìúÏãú Î¶¨ÏÇ¨Ïù¥Ï¶àÌï¥ÏÑú Ï∞®Ïõê Í≥†Ï†ï)\n",
    "X_hog_train = extract_hog_full(\n",
    "    Training_origin_data,\n",
    "    hog_sizes=((256, 128),),      \n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    ")\n",
    "X_hog_test = extract_hog_full(\n",
    "    Test_data,\n",
    "    hog_sizes=((256, 128),),\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    ")\n",
    "\n",
    "print(\"X_color_train:\", X_color_train.shape, X_color_train.dtype)\n",
    "print(\"X_hog_train  :\", X_hog_train.shape,   X_hog_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6bc0eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 2) Scaling\n",
    "# =========================\n",
    "sc_color = StandardScaler()\n",
    "Xc_tr = sc_color.fit_transform(X_color_train)\n",
    "Xc_te = sc_color.transform(X_color_test)\n",
    "\n",
    "# HOGÎäî PCA+SVM Ìï®Ïàò ÏïàÏóêÏÑú scalerÎ•º Îî∞Î°ú Ïì∞Îäî Íµ¨Ï°∞Í∞Ä ÎßéÏïÑÏÑú\n",
    "# Ïó¨Í∏∞ÏÑúÎäî \"raw HOG\"Î•º Í∑∏ÎåÄÎ°ú ÎÑòÍπÄ (ÎÑàÍ∞Ä Ïì∞Îçò Î∞©Ïãù Ïú†ÏßÄ)\n",
    "Xh_tr, Xh_te = X_hog_train, X_hog_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "39ae4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[COLOR] result: {'name': 'COLOR_SVM', 'train_acc': 0.9627969520394442, 'test_acc': 0.7012113055181696, 'pred_sec': 0.31446190499991644}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 3) Train COLOR SVM + Evaluate\n",
    "# =========================\n",
    "svm_color = train_color_svm(Xc_tr, y_train_road, C=10, gamma=\"scale\")\n",
    "res_color = eval_svm(svm_color, Xc_tr, y_train_road, Xc_te, y_test_road, name=\"COLOR_SVM\")\n",
    "\n",
    "print(\"\\n[COLOR] result:\", res_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fb42bc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HOG PCA+SVM] leaderboard\n",
      "    dim  train_acc  test_acc  total_sec\n",
      "1   64   1.000000  0.504711   1.694379\n",
      "0   32   0.999552  0.499327   1.832274\n",
      "2  128   1.000000  0.484522   2.014503\n",
      "3  256   1.000000  0.422611   2.522735\n",
      "\n",
      "‚úÖ best_dim = 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 4) Train HOG PCA+SVM by dims + pick best\n",
    "# =========================\n",
    "pca_dims = [32, 64, 128, 256]   # ÌïÑÏöîÌïòÎ©¥ Ï°∞Ï†à\n",
    "hog_result = train_hog_pca_svm_by_dims(\n",
    "    Xh_tr, y_train_road,\n",
    "    Xh_te, y_test_road,\n",
    "    pca_dims=pca_dims,\n",
    "    C=10,\n",
    "    gamma=\"scale\",\n",
    ")\n",
    "\n",
    "df_hog = pd.DataFrame({\n",
    "    \"dim\": pca_dims,\n",
    "    \"train_acc\": [hog_result[\"train_acc\"][d] for d in pca_dims],\n",
    "    \"test_acc\":  [hog_result[\"test_acc\"][d]  for d in pca_dims],\n",
    "    \"total_sec\": [hog_result[\"time_report\"][d][\"total_sec\"] for d in pca_dims],\n",
    "}).sort_values(\"test_acc\", ascending=False)\n",
    "\n",
    "print(\"\\n[HOG PCA+SVM] leaderboard\\n\", df_hog)\n",
    "\n",
    "best_dim = int(df_hog.iloc[0][\"dim\"])\n",
    "print(\"\\n‚úÖ best_dim =\", best_dim)\n",
    "\n",
    "# best Î™®Îç∏ Í∫ºÎÇ¥Í∏∞ (ÎÑàÍ∞Ä Ïì∞Îçò pack Íµ¨Ï°∞ Í∏∞Ï§Ä)\n",
    "hog_pack = hog_result[\"pack\"] if \"pack\" in hog_result else hog_result  # Î∞©Ïñ¥ÏΩîÎìú\n",
    "hog_scaler = hog_pack[\"hog_pca_models\"][best_dim][0]\n",
    "hog_pca    = hog_pack[\"hog_pca_models\"][best_dim][1]\n",
    "svm_hog    = hog_pack[\"hog_svm_models\"][best_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4da2a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row-sum check: 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) Calibration -> probability (COLOR/HOG)  ‚úÖ custom\n",
    "# =========================\n",
    "# (1) HOGÎäî PCAÎêú featureÎ°ú ÌôïÎ•†ÏùÑ ÎßåÎì§Ïñ¥Ïïº Ìï®\n",
    "Xh_tr_p = hog_pca.transform(hog_scaler.transform(Xh_tr))\n",
    "Xh_te_p = hog_pca.transform(hog_scaler.transform(Xh_te))\n",
    "\n",
    "# (2) calibratorÎäî \"train feature\"Î°ú fit\n",
    "cal_color = fit_sigmoid_calibrator(\n",
    "    svm_color, Xc_tr, y_train_road,\n",
    "    q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95\n",
    ")\n",
    "cal_hog = fit_sigmoid_calibrator(\n",
    "    svm_hog, Xh_tr_p, y_train_road,\n",
    "    q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95\n",
    ")\n",
    "\n",
    "# (3) testÏóêÏÑú custom ÌôïÎ•† ÏÉùÏÑ±\n",
    "P_color = predict_proba_custom(\n",
    "    svm_color, Xc_te,\n",
    "    method=\"sigmoid\", calibrator=cal_color, power=1.0\n",
    ")\n",
    "P_hog = predict_proba_custom(\n",
    "    svm_hog, Xh_te_p,\n",
    "    method=\"sigmoid\", calibrator=cal_hog, power=1.0\n",
    ")\n",
    "\n",
    "print(\"row-sum check:\", float(P_color[0].sum()), float(P_hog[0].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2664bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- train ÌôïÎ•†ÎèÑ ÎßåÎì§Ïñ¥Ïïº LR-fusion ÌïôÏäµ Í∞ÄÎä• ---\n",
    "P_color_tr = predict_proba_custom(svm_color, Xc_tr,  method=\"sigmoid\", calibrator=cal_color, power=1.0)\n",
    "P_hog_tr   = predict_proba_custom(svm_hog,   Xh_tr_p, method=\"sigmoid\", calibrator=cal_hog,   power=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f4864826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ alpha_hat(shape) = 0.618\n",
      "SCORES: {'HOG': 0.46837146702557203, 'COLOR': 0.6783310901749664, 'FUSION(LR)': 0.5531628532974427}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =========================\n",
    "# 6) Fusion (LR) + alpha_hat\n",
    "# =========================\n",
    "K = P_color.shape[1]\n",
    "assert P_hog.shape == P_color.shape, \"P_hog / P_color shape mismatch\"\n",
    "\n",
    "# (1) LR ÌïôÏäµÏö© ÏûÖÎ†•: (N_train, 2K)\n",
    "X_fuse_tr = np.hstack([P_hog_tr, P_color_tr])\n",
    "\n",
    "# (2) LR ÌïôÏäµ (Í∂åÏû•: train ÎùºÎ≤®Î°ú fit)\n",
    "lr_fusion = LogisticRegression(solver=\"lbfgs\", max_iter=2000)\n",
    "lr_fusion.fit(X_fuse_tr, y_train_road)\n",
    "\n",
    "# (3) testÏóêÏÑú fusion ÌôïÎ•†\n",
    "X_fuse_te = np.hstack([P_hog, P_color])\n",
    "P_final = lr_fusion.predict_proba(X_fuse_te)\n",
    "\n",
    "# (4) ÏÑ±Îä•\n",
    "final_acc, final_pred = evaluate_fusion(P_final, y_test_road)\n",
    "acc_hog,   _ = evaluate_fusion(P_hog,   y_test_road)\n",
    "acc_color, _ = evaluate_fusion(P_color, y_test_road)\n",
    "\n",
    "# (5) alpha_hat Ï∂îÏ†ï (shape ÏòÅÌñ• ÎπÑÏ§ë)\n",
    "W = lr_fusion.coef_               # (K, 2K)\n",
    "w_shape = float(np.mean(np.abs(W[:, :K])))\n",
    "w_color = float(np.mean(np.abs(W[:, K:])))\n",
    "alpha_hat = float(w_shape / (w_shape + w_color + 1e-12))\n",
    "\n",
    "print(f\"‚úÖ alpha_hat(shape) = {alpha_hat:.3f}\")\n",
    "print(\"SCORES:\", {\"HOG\": acc_hog, \"COLOR\": acc_color, \"FUSION(LR)\": final_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "966fd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Models saved\n",
      "Dir = FPL_models\n",
      "Tag = FULL64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 7) Save models (FULL: color+hog only)\n",
    "# =========================\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "tag = f\"FULL{best_dim}\"\n",
    "\n",
    "# ---- road models ----\n",
    "joblib.dump(svm_hog,    f\"{MODEL_DIR}/hog_svm_{tag}.pkl\")\n",
    "joblib.dump(hog_pca,    f\"{MODEL_DIR}/hog_pca_{tag}.pkl\")\n",
    "joblib.dump(hog_scaler, f\"{MODEL_DIR}/hog_scaler_{tag}.pkl\")\n",
    "\n",
    "joblib.dump(svm_color,  f\"{MODEL_DIR}/color_svm_{tag}.pkl\")\n",
    "joblib.dump(sc_color,   f\"{MODEL_DIR}/color_scaler_{tag}.pkl\")\n",
    "\n",
    "# ---- calibrators ----\n",
    "joblib.dump(cal_hog,    f\"{MODEL_DIR}/cal_hog_{tag}.pkl\")\n",
    "joblib.dump(cal_color,  f\"{MODEL_DIR}/cal_color_{tag}.pkl\")\n",
    "\n",
    "\n",
    "# ---- label map (ÏûàÏúºÎ©¥) ----\n",
    "if \"road_label_map\" in globals():\n",
    "    joblib.dump(road_label_map, f\"{MODEL_DIR}/road_label_map_{tag}.pkl\")\n",
    "\n",
    "\n",
    "joblib.dump(lr_fusion, f\"{MODEL_DIR}/fusion_lr_{tag}.pkl\")\n",
    "joblib.dump({\"alpha_hat\": alpha_hat}, f\"{MODEL_DIR}/fusion_alpha_{tag}.pkl\")\n",
    "\n",
    "# ---- meta ----\n",
    "joblib.dump({\n",
    "    \"hog_resize\": (256, 256),\n",
    "    \"hog_orientations\": 12,\n",
    "    \"hog_pixels_per_cell\": (8, 8),\n",
    "    \"hog_cells_per_block\": (2, 2),\n",
    "    \"color_h_bins\": 60,\n",
    "    \"color_s_bins\": 64,\n",
    "    \"best_dim\": best_dim,\n",
    "}, f\"{MODEL_DIR}/meta_{tag}.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Models saved\")\n",
    "print(\"Dir =\", MODEL_DIR)\n",
    "print(\"Tag =\", tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d861983",
   "metadata": {},
   "source": [
    "detail_SVM and kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0bdab585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_knn_models.py\n",
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_detail_models.py\n",
      "new signature: (X_hog_train, X_color_train, training_road_label, training_detail, training_x, training_y, out_dir, hog_pca_dim=128, n_neighbors=7, detail_roads={'donhwamunro_11_ga', 'donhwamunro_11_na', 'donhwamunro_11_da', 'suporo_28'}, min_samples=10, training_paths=None, feature_tag='full')\n"
     ]
    }
   ],
   "source": [
    "import importlib, inspect\n",
    "import fpl_knn_models\n",
    "import fpl_detail_models\n",
    "\n",
    "print(\"loaded from:\", fpl_knn_models.__file__)\n",
    "importlib.reload(fpl_knn_models)\n",
    "print(\"loaded from:\", fpl_detail_models.__file__)\n",
    "importlib.reload(fpl_detail_models)\n",
    "\n",
    "print(\"new signature:\", inspect.signature(fpl_knn_models.train_and_save_knn_models))\n",
    "\n",
    "# ‚úÖ Ïù¥ Ï§ÑÏù¥ Ï§ëÏöî: Î°úÏª¨ Ïù¥Î¶ÑÏùÑ 'ÏÉà Ìï®Ïàò'Î°ú Îã§Ïãú Î∞îÏù∏Îî©\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1385cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] detail(FULL64) road=donhwamunro_11_da | classes=['A', 'B', 'C'] | n=177 | pca=64\n",
      "[SAVED] detail(FULL64) road=donhwamunro_11_ga | classes=['A', 'B', 'C'] | n=213 | pca=64\n",
      "[SAVED] detail(FULL64) road=donhwamunro_11_na | classes=['A', 'B', 'C', 'D'] | n=300 | pca=64\n",
      "[SAVED] detail(FULL64) road=suporo_28 | classes=['A', 'B', 'C', 'D', 'E'] | n=296 | pca=64\n",
      "[SAVED] KNN(FULL64) road=donhwamunro | n=189\n",
      "[SAVED] KNN(FULL64) road=donhwamunro_11 | n=130\n",
      "[SAVED] KNN(FULL64) road=donhwamunro_11_da | n=177\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_da detail=A | n=90\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_da detail=B | n=49\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_da detail=C | n=38\n",
      "[SAVED] KNN(FULL64) road=donhwamunro_11_ga | n=213\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_ga detail=A | n=46\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_ga detail=B | n=79\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_ga detail=C | n=88\n",
      "[SAVED] KNN(FULL64) road=donhwamunro_11_na | n=300\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_na detail=A | n=67\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_na detail=B | n=126\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_na detail=C | n=55\n",
      "  [SAVED] KNN(FULL64) road=donhwamunro_11_na detail=D | n=52\n",
      "[SAVED] KNN(FULL64) road=samildaero | n=199\n",
      "[SAVED] KNN(FULL64) road=samildaero_26 | n=79\n",
      "[SAVED] KNN(FULL64) road=samildaero_28 | n=114\n",
      "[SAVED] KNN(FULL64) road=samildaero_30 | n=176\n",
      "[SAVED] KNN(FULL64) road=samildaero_32 | n=229\n",
      "[SAVED] KNN(FULL64) road=samildaero_32_ga | n=129\n",
      "[SAVED] KNN(FULL64) road=suporo_28 | n=296\n",
      "  [SAVED] KNN(FULL64) road=suporo_28 detail=A | n=104\n",
      "  [SAVED] KNN(FULL64) road=suporo_28 detail=B | n=60\n",
      "  [SAVED] KNN(FULL64) road=suporo_28 detail=C | n=38\n",
      "  [SAVED] KNN(FULL64) road=suporo_28 detail=D | n=61\n",
      "  [SAVED] KNN(FULL64) road=suporo_28 detail=E | n=33\n",
      "‚úÖ KNN saved under: FPL_models/knn_models_FULL64\n"
     ]
    }
   ],
   "source": [
    "# ---- reload ----\n",
    "import importlib, inspect\n",
    "import fpl_knn_models\n",
    "import fpl_detail_models\n",
    "\n",
    "importlib.reload(fpl_knn_models)\n",
    "importlib.reload(fpl_detail_models)\n",
    "\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n",
    "\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "feature_tag = tag                \n",
    "ALPHA_FIXED = float(alpha_hat)       \n",
    "\n",
    "\n",
    "detail_pack = train_and_save_detail_models(\n",
    "    X_hog_train=Xh_tr_p,         \n",
    "    X_color_train=Xc_tr,         \n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    out_dir=MODEL_DIR,\n",
    "    alpha_shape=ALPHA_FIXED,\n",
    "    hog_pca_dim=best_dim,        \n",
    "    C=10, gamma=\"scale\",\n",
    "    min_total_samples=20,\n",
    "    min_samples_per_detail=8,\n",
    "    feature_tag=feature_tag,\n",
    ")\n",
    "\n",
    "\n",
    "knn_pack = train_and_save_knn_models(\n",
    "    X_hog_train=X_hog_train,\n",
    "    X_color_train=Xc_tr,\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    training_x=training_x,\n",
    "    training_y=training_y,\n",
    "    out_dir=MODEL_DIR,\n",
    "    hog_pca_dim=best_dim,        \n",
    "    n_neighbors=10,\n",
    "    min_samples=10,\n",
    "    training_paths=training_paths,\n",
    "    feature_tag=feature_tag,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d18bd625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_root = FPL_models/knn_models_FULL64\n",
      "‚úÖ loaded: knn_hog_scaler_pca64.pkl knn_hog_pca_pca64.pkl\n",
      "Z_test shape: (743, 188)\n",
      "ok preds: 743 / 743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_eval</th>\n",
       "      <th>mae_x</th>\n",
       "      <th>rmse_x</th>\n",
       "      <th>mae_y</th>\n",
       "      <th>rmse_y</th>\n",
       "      <th>mae_dist</th>\n",
       "      <th>rmse_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743</td>\n",
       "      <td>0.535089</td>\n",
       "      <td>0.774125</td>\n",
       "      <td>0.53916</td>\n",
       "      <td>0.892549</td>\n",
       "      <td>0.883208</td>\n",
       "      <td>1.181488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_eval     mae_x    rmse_x    mae_y    rmse_y  mae_dist  rmse_dist\n",
       "0     743  0.535089  0.774125  0.53916  0.892549  0.883208   1.181488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road</th>\n",
       "      <th>mae_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>samildaero</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>samildaero_32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>samildaero_26</td>\n",
       "      <td>0.182142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>samildaero_28</td>\n",
       "      <td>0.482632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>samildaero_32_ga</td>\n",
       "      <td>0.707347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donhwamunro_11</td>\n",
       "      <td>0.906444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donhwamunro_11_da</td>\n",
       "      <td>1.044528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donhwamunro</td>\n",
       "      <td>1.068730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>suporo_28</td>\n",
       "      <td>1.120410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>donhwamunro_11_na</td>\n",
       "      <td>1.326793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>samildaero_30</td>\n",
       "      <td>1.409852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donhwamunro_11_ga</td>\n",
       "      <td>1.560701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 road  mae_dist\n",
       "5          samildaero  0.000000\n",
       "9       samildaero_32  0.000000\n",
       "6       samildaero_26  0.182142\n",
       "7       samildaero_28  0.482632\n",
       "10   samildaero_32_ga  0.707347\n",
       "1      donhwamunro_11  0.906444\n",
       "2   donhwamunro_11_da  1.044528\n",
       "0         donhwamunro  1.068730\n",
       "11          suporo_28  1.120410\n",
       "4   donhwamunro_11_na  1.326793\n",
       "8       samildaero_30  1.409852\n",
       "3   donhwamunro_11_ga  1.560701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, json, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# -------------------------\n",
    "# 0) Ïú†Ìã∏\n",
    "# -------------------------\n",
    "def clean_detail_arr(detail_arr):\n",
    "    out = []\n",
    "    for d in detail_arr:\n",
    "        if d is None:\n",
    "            out.append(\"0\"); continue\n",
    "        s = str(d).strip()\n",
    "        if s.lower() in (\"nan\", \"none\", \"\"):\n",
    "            out.append(\"0\")\n",
    "        else:\n",
    "            out.append(s)\n",
    "    return np.array(out, dtype=object)\n",
    "\n",
    "def knn_root_from_tag(model_dir, feature_tag):\n",
    "    ft = (feature_tag or \"\").strip()\n",
    "    if ft in (\"\", \"legacy\"):\n",
    "        return os.path.join(model_dir, \"knn_models\")\n",
    "    return os.path.join(model_dir, f\"knn_models_{ft}\")\n",
    "\n",
    "def load_knn_global_scaler_pca(knn_root, pca_dim):\n",
    "    scaler_path = os.path.join(knn_root, f\"knn_hog_scaler_pca{pca_dim}.pkl\")\n",
    "    pca_path    = os.path.join(knn_root, f\"knn_hog_pca_pca{pca_dim}.pkl\")\n",
    "    if not (os.path.exists(scaler_path) and os.path.exists(pca_path)):\n",
    "        raise FileNotFoundError(f\"‚ùó scaler/pca not found:\\n{scaler_path}\\n{pca_path}\")\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    pca    = joblib.load(pca_path)\n",
    "    print(\"‚úÖ loaded:\", os.path.basename(scaler_path), os.path.basename(pca_path))\n",
    "    return scaler, pca\n",
    "\n",
    "def build_Z(X_hog, X_color, scaler, pca):\n",
    "    Xh_p = pca.transform(scaler.transform(X_hog))\n",
    "    return np.hstack([Xh_p, X_color])\n",
    "\n",
    "# -------------------------\n",
    "# 1) Í≤ΩÎ°ú/Î°úÎìú\n",
    "# -------------------------\n",
    "KNN_PCA_DIM = int(best_dim)  # ÎÑà ÏΩîÎìúÏóêÏÑú best_dim Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n",
    "knn_root = knn_root_from_tag(MODEL_DIR, feature_tag)\n",
    "print(\"knn_root =\", knn_root)\n",
    "\n",
    "hog_scaler_knn, hog_pca_knn = load_knn_global_scaler_pca(knn_root, KNN_PCA_DIM)\n",
    "\n",
    "# -------------------------\n",
    "# 2) test feature Î≥ÄÌôò (üî• KNNÏùÄ 'KNNÏö© scaler/pca'Î°ú Î≥ÄÌôòÌï¥Ïïº Ìï®)\n",
    "# -------------------------\n",
    "# ‚ö†Ô∏è Ï£ºÏùò: X_hog_testÎäî \"raw HOG\" Ïó¨Ïïº Ìï®. (ÏßÄÍ∏à ÏÖÄÏóêÏÑúÎäî full raw hogÎ°ú Ï∂îÏ∂úÌïú ÏÉÅÌÉú)\n",
    "#         ÎßåÏïΩ X_hog_testÍ∞Ä Ïù¥ÎØ∏ PCAÎêú Í±∏ ÎÑ£ÏúºÎ©¥ Ï∞®Ïõê Íπ®Ï†∏ÏÑú ÏóêÎü¨ÎÇ®.\n",
    "Z_test = build_Z(X_hog_test, X_color_test, hog_scaler_knn, hog_pca_knn)\n",
    "print(\"Z_test shape:\", Z_test.shape)\n",
    "\n",
    "# -------------------------\n",
    "# 3) ÎèÑÎ°úÎ≥Ñ KNN ÏòàÏ∏° (road-level)\n",
    "# -------------------------\n",
    "road_arr  = np.asarray(test_road_label, dtype=object)   # Î¨∏ÏûêÏó¥ ÎèÑÎ°úÎ™Ö\n",
    "dt_arr    = clean_detail_arr(test_detail)               # detail Î¨∏ÏûêÏó¥ (ÏóÜÏúºÎ©¥ \"0\")\n",
    "\n",
    "pred_x = np.full(len(road_arr), np.nan, dtype=np.float32)\n",
    "pred_y = np.full(len(road_arr), np.nan, dtype=np.float32)\n",
    "ok = np.zeros(len(road_arr), dtype=bool)\n",
    "\n",
    "missing_models = {}\n",
    "\n",
    "for i in range(len(road_arr)):\n",
    "    road = road_arr[i]\n",
    "    model_path = os.path.join(knn_root, road, \"knn_road.pkl\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        key = (road, \"road\")\n",
    "        missing_models[key] = missing_models.get(key, 0) + 1\n",
    "        continue\n",
    "\n",
    "    knn = joblib.load(model_path)\n",
    "    xy_hat = knn.predict(Z_test[i].reshape(1, -1)).ravel()\n",
    "    pred_x[i], pred_y[i] = float(xy_hat[0]), float(xy_hat[1])\n",
    "    ok[i] = True\n",
    "\n",
    "print(\"ok preds:\", int(ok.sum()), \"/\", len(ok))\n",
    "\n",
    "if ok.sum() == 0:\n",
    "    print(\"‚ùó ÏòàÏ∏° ÏÑ±Í≥µÌïú ÏÉòÌîåÏù¥ ÏóÜÏñ¥ÏÑú ÌèâÍ∞Ä Î∂àÍ∞Ä.\")\n",
    "    print(\"missing model examples:\", sorted(missing_models.items(), key=lambda x: -x[1])[:10])\n",
    "else:\n",
    "    # -------------------------\n",
    "    # 4) ÌèâÍ∞Ä (test_x/test_y ÏûàÏùÑ Îïå)\n",
    "    # -------------------------\n",
    "    if (\"test_x\" in globals()) and (\"test_y\" in globals()):\n",
    "        gt_x = np.asarray(test_x, dtype=np.float32)\n",
    "        gt_y = np.asarray(test_y, dtype=np.float32)\n",
    "\n",
    "        # Ïú†Ìö®Ìïú gt + ÏòàÏ∏° ÏÑ±Í≥µÎßå\n",
    "        valid = ok & np.isfinite(gt_x) & np.isfinite(gt_y)\n",
    "        n_eval = int(valid.sum())\n",
    "\n",
    "        if n_eval == 0:\n",
    "            print(\"‚ö†Ô∏è test_x/test_yÍ∞Ä ÏûàÏßÄÎßå Ïú†Ìö®Ìïú Ï¢åÌëúÍ∞Ä ÏóÜÏñ¥ÏÑú Ïä§ÌÇµ\")\n",
    "        else:\n",
    "            dx = pred_x[valid] - gt_x[valid]\n",
    "            dy = pred_y[valid] - gt_y[valid]\n",
    "            dist = np.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "            mae_x = float(np.mean(np.abs(dx)))\n",
    "            rmse_x = float(np.sqrt(np.mean(dx*dx)))\n",
    "            mae_y = float(np.mean(np.abs(dy)))\n",
    "            rmse_y = float(np.sqrt(np.mean(dy*dy)))\n",
    "            mae_dist = float(np.mean(dist))\n",
    "            rmse_dist = float(np.sqrt(np.mean(dist*dist)))\n",
    "\n",
    "            overall = pd.DataFrame([{\n",
    "                \"n_eval\": n_eval,\n",
    "                \"mae_x\": mae_x, \"rmse_x\": rmse_x,\n",
    "                \"mae_y\": mae_y, \"rmse_y\": rmse_y,\n",
    "                \"mae_dist\": mae_dist, \"rmse_dist\": rmse_dist,\n",
    "            }])\n",
    "            display(overall)\n",
    "\n",
    "            # road-wise\n",
    "            rows = []\n",
    "            for r in sorted(set(road_arr[valid])):\n",
    "                idx = valid & (road_arr == r)\n",
    "                if idx.sum() == 0: \n",
    "                    continue\n",
    "                dxr = pred_x[idx] - gt_x[idx]\n",
    "                dyr = pred_y[idx] - gt_y[idx]\n",
    "                dist_r = np.sqrt(dxr*dxr + dyr*dyr)\n",
    "                rows.append({\"road\": r, \"mae_dist\": float(np.mean(dist_r))})\n",
    "\n",
    "            roadwise = pd.DataFrame(rows).sort_values(\"mae_dist\")\n",
    "            display(roadwise)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è test_x/test_yÍ∞Ä ÏóÜÏñ¥ÏÑú 'ÏòàÏ∏° ÏÉùÏÑ±'ÍπåÏßÄÎßå ÏôÑÎ£å (ÌèâÍ∞Ä ÏßÄÌëúÎäî Ïä§ÌÇµ)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "411e3027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleanup done: freed FULL/knn intermediate variables.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# -------------------------\n",
    "# FULL pipeline ÎåÄÏö©Îüâ Î≥ÄÏàò Ï†ïÎ¶¨\n",
    "# -------------------------\n",
    "to_del = [\n",
    "    # raw/full features\n",
    "    \"X_color_train\", \"X_color_test\",\n",
    "    \"X_hog_train\", \"X_hog_test\",\n",
    "    \"Xc_tr\", \"Xc_te\",\n",
    "    \"Xh_tr\", \"Xh_te\",\n",
    "    \"Xh_tr_p\", \"Xh_te_p\",\n",
    "\n",
    "    # probabilities / fusion\n",
    "    \"P_color\", \"P_hog\", \"P_color_tr\", \"P_hog_tr\",\n",
    "    \"X_fuse_tr\", \"X_fuse_te\", \"P_final\",\n",
    "    \"final_pred\",\n",
    "\n",
    "    # models/calibrators\n",
    "    \"svm_color\", \"svm_hog\",\n",
    "    \"hog_scaler\", \"hog_pca\",\n",
    "    \"cal_color\", \"cal_hog\",\n",
    "    \"lr_fusion\",\n",
    "\n",
    "    # hog search packs\n",
    "    \"hog_result\", \"hog_pack\", \"df_hog\",\n",
    "\n",
    "    # detail/knn packs\n",
    "    \"detail_pack\", \"knn_pack\",\n",
    "\n",
    "    # KNN eval intermediates\n",
    "    \"hog_scaler_knn\", \"hog_pca_knn\",\n",
    "    \"Z_test\", \"pred_x\", \"pred_y\", \"ok\",\n",
    "    \"missing_models\",\n",
    "]\n",
    "\n",
    "for v in to_del:\n",
    "    if v in globals():\n",
    "        del globals()[v]\n",
    "\n",
    "gc.collect()\n",
    "print(\"‚úÖ Cleanup done: freed FULL/knn intermediate variables.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
