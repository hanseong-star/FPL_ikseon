{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c2bc90",
   "metadata": {},
   "source": [
    "FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40db64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/hanseong/vscode/ML_code/FPL/FPL\n",
      "SRC_DIR: /home/hanseong/vscode/ML_code/FPL/FPL/src\n",
      "SRC exists?: True\n",
      "sys.path[0]: /home/hanseong/vscode/ML_code/FPL/FPL/src\n",
      "imports OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().resolve()   # 보통 FPL 폴더에서 노트북 실행중이면 이게 루트\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 현재 노트북이 있는 폴더(FPL) 기준으로 src 절대경로 계산\n",
    "SRC_DIR = (Path(os.getcwd()) / \"src\").resolve()\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"SRC_DIR:\", SRC_DIR)\n",
    "print(\"SRC exists?:\", SRC_DIR.exists())\n",
    "\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.fpl_data_io import build_image_index, load_dataset\n",
    "from src.fpl_features import extract_color_hs_3x3, extract_hog_3x3\n",
    "from src.fpl_models import encode_road_labels, train_color_svm, train_hog_pca_svm_by_dims\n",
    "from src.fpl_fusion import fuse_probabilities\n",
    "from src.fpl_metrics import eval_accuracy, eval_confusion, eval_report\n",
    "from src.fpl_detail_models import train_and_save_detail_models\n",
    "from src.fpl_knn_models import train_and_save_knn_models\n",
    "\n",
    "from src.fpl_features import (\n",
    "    extract_color_hs_full,\n",
    "    extract_hog_full,\n",
    "    extract_lbp_full,\n",
    ")\n",
    "\n",
    "from src.fpl_models import (\n",
    "    encode_road_labels,\n",
    "    train_color_svm,\n",
    "    train_lbp_svm,\n",
    "    train_hog_pca_svm_by_dims,\n",
    "    eval_svm,\n",
    "    fit_sigmoid_calibrator,\n",
    "    predict_proba_custom,\n",
    "    fuse_probabilities,\n",
    "    evaluate_fusion,\n",
    ")\n",
    "\n",
    "print(\"imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a9f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "TRAINING_LABEL_CSV = \"/home/hanseong/gdrive/ML_FPL_training_data/training_labels_plus.csv\"\n",
    "TEST_LABEL_CSV  = \"/home/hanseong/gdrive/ML_FPL_test_data/test_labels_plus.csv\"\n",
    "\n",
    "test_path = \"/home/hanseong/gdrive/ML_FPL_test_data\"\n",
    "training_path = \"/home/hanseong/gdrive/ML_FPL_training_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8767a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed files: 2974\n",
      "sample: [('donhwamunro_11_da_A_raw_0824.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0824.jpg'), ('donhwamunro_11_da_A_raw_0825.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0825.jpg'), ('donhwamunro_11_da_A_raw_0826.jpg', '/home/hanseong/gdrive/ML_FPL_training_data/jpg/donhwamunro_11_da_A_raw_0826.jpg')]\n"
     ]
    }
   ],
   "source": [
    "# training/test 폴더 둘 다 훑어서 filename -> fullpath 인덱스 생성\n",
    "image_index = build_image_index(training_path, test_path)\n",
    "\n",
    "print(\"indexed files:\", len(image_index))\n",
    "print(\"sample:\", list(image_index.items())[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ac674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images: 2231 missed: 0\n",
      "Loaded test  images: 743 missed: 0\n",
      "Train sample image shapes: {(682, 1024, 3)}\n",
      "Test  sample image shapes: {(682, 1024, 3)}\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(TRAINING_LABEL_CSV, image_index, resize=True)\n",
    "test  = load_dataset(TEST_LABEL_CSV, image_index, resize=True)\n",
    "\n",
    "Training_origin_data = train[\"images\"]\n",
    "Test_data = test[\"images\"]\n",
    "\n",
    "training_road_label = train[\"road_labels\"]\n",
    "test_road_label = test[\"road_labels\"]\n",
    "\n",
    "training_photo_id = train[\"photo_ids\"]\n",
    "test_photo_id = test[\"photo_ids\"]\n",
    "\n",
    "training_detail = train[\"details\"]\n",
    "test_detail = test[\"details\"]\n",
    "\n",
    "training_filename = train[\"filenames\"]\n",
    "test_filename = test[\"filenames\"]\n",
    "\n",
    "print(\"Loaded train images:\", len(Training_origin_data), \"missed:\", len(train[\"missed\"]))\n",
    "print(\"Loaded test  images:\", len(Test_data), \"missed:\", len(test[\"missed\"]))\n",
    "\n",
    "print(\"Train sample image shapes:\", {Training_origin_data[i].shape for i in range(min(5, len(Training_origin_data)))})\n",
    "print(\"Test  sample image shapes:\", {Test_data[i].shape for i in range(min(5, len(Test_data)))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bf032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = train[\"xs\"]; training_y = train[\"ys\"]\n",
    "test_x     = test[\"xs\"];  test_y     = test[\"ys\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e731d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num roads: 12\n",
      "y_train_road unique: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "y_test_road  unique: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "road_label_map sample: [('donhwamunro', 0), ('donhwamunro_11', 1), ('donhwamunro_11_da', 2), ('donhwamunro_11_ga', 3), ('donhwamunro_11_na', 4), ('samildaero', 5), ('samildaero_26', 6), ('samildaero_28', 7), ('samildaero_30', 8), ('samildaero_32', 9), ('samildaero_32_ga', 10), ('suporo_28', 11)]\n"
     ]
    }
   ],
   "source": [
    "y_train_road, y_test_road, road_label_map = encode_road_labels(training_road_label, test_road_label)\n",
    "\n",
    "print(\"num roads:\", len(road_label_map))\n",
    "print(\"y_train_road unique:\", np.unique(y_train_road))\n",
    "print(\"y_test_road  unique:\", np.unique(y_test_road))\n",
    "\n",
    "# 매핑 일부 확인\n",
    "items = list(road_label_map.items())\n",
    "print(\"road_label_map sample:\", items[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7268c8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hog_train: (2231, 72900)\n",
      "X_hog_test : (743, 72900)\n",
      "X_color_train: (2231, 558)\n",
      "X_color_test : (743, 558)\n"
     ]
    }
   ],
   "source": [
    "# HOG\n",
    "X_hog_train = extract_hog_3x3(\n",
    "    Training_origin_data,\n",
    "    hog_size=(128, 128),\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2)\n",
    ")\n",
    "X_hog_test = extract_hog_3x3(\n",
    "    Test_data,\n",
    "    hog_size=(128, 128),\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2)\n",
    ")\n",
    "\n",
    "print(\"X_hog_train:\", X_hog_train.shape)\n",
    "print(\"X_hog_test :\", X_hog_test.shape)\n",
    "\n",
    "# Color (H,S)\n",
    "X_color_train = extract_color_hs_3x3(Training_origin_data, h_bins=30, s_bins=32)\n",
    "X_color_test  = extract_color_hs_3x3(Test_data, h_bins=30, s_bins=32)\n",
    "\n",
    "print(\"X_color_train:\", X_color_train.shape)\n",
    "print(\"X_color_test :\", X_color_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f04717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_color_test: (743, 12)\n",
      "Color SVM Test Accuracy: 0.7254374158815612\n",
      "\n",
      "Color SVM Confusion Matrix:\n",
      " [[49  1  0  0  6  0  0  0  2  2  2  0]\n",
      " [ 2 35  0  0  1  0  0  2  0  0  1  2]\n",
      " [ 0  0 39  1  3  2  2  1  1  1  0  8]\n",
      " [ 2  0  0 44 11  3  0  0  2  3  5  2]\n",
      " [ 1  1  5  9 65  3  0  0  4  5  6  1]\n",
      " [ 2  1  2  1  1 51  0  1  0  3  2  2]\n",
      " [ 0  1  1  2  0  0 21  1  0  0  0  0]\n",
      " [ 0  3  1  2  2  1  0 25  0  1  1  2]\n",
      " [ 0  2  0  0  4  1  0  1 47  3  0  1]\n",
      " [ 1  0  0  2  8  4  0  2  3 58  0  1]\n",
      " [ 0  0  1  2  6  3  0  0  1  2 27  1]\n",
      " [ 2  1  2  3  5  1  3  0  0  0  2 78]]\n",
      "\n",
      "Color SVM Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8305    0.7903    0.8099        62\n",
      "           1     0.7778    0.8140    0.7955        43\n",
      "           2     0.7647    0.6724    0.7156        58\n",
      "           3     0.6667    0.6111    0.6377        72\n",
      "           4     0.5804    0.6500    0.6132       100\n",
      "           5     0.7391    0.7727    0.7556        66\n",
      "           6     0.8077    0.8077    0.8077        26\n",
      "           7     0.7576    0.6579    0.7042        38\n",
      "           8     0.7833    0.7966    0.7899        59\n",
      "           9     0.7436    0.7342    0.7389        79\n",
      "          10     0.5870    0.6279    0.6067        43\n",
      "          11     0.7959    0.8041    0.8000        97\n",
      "\n",
      "    accuracy                         0.7254       743\n",
      "   macro avg     0.7362    0.7282    0.7312       743\n",
      "weighted avg     0.7285    0.7254    0.7260       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.fpl_models import train_color_svm, train_hog_pca_svm_by_dims\n",
    "color_svm = train_color_svm(X_color_train, y_train_road, C=10, gamma=\"scale\")\n",
    "P_color_test = color_svm.predict_proba(X_color_test)\n",
    "\n",
    "print(\"P_color_test:\", P_color_test.shape)\n",
    "\n",
    "# 1) test 예측 라벨 (확률이 가장 큰 클래스)\n",
    "y_pred_color = np.argmax(P_color_test, axis=1)\n",
    "\n",
    "# 2) 정확도\n",
    "acc_color = eval_accuracy(y_test_road, y_pred_color)\n",
    "print(\"Color SVM Test Accuracy:\", acc_color)\n",
    "\n",
    "# 3) confusion matrix + report\n",
    "cm_color = eval_confusion(y_test_road, y_pred_color)\n",
    "print(\"\\nColor SVM Confusion Matrix:\\n\", cm_color)\n",
    "\n",
    "print(\"\\nColor SVM Classification Report:\\n\")\n",
    "print(eval_report(y_test_road, y_pred_color))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ebb411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HOG+PCA SVM summary =====\n",
      "PCA   2 | Test Acc=0.1965 | scale=1.120s pca=0.638s svm=0.857s total=2.797s\n",
      "PCA   8 | Test Acc=0.3580 | scale=1.138s pca=0.727s svm=0.750s total=2.790s\n",
      "PCA  16 | Test Acc=0.4980 | scale=1.096s pca=0.866s svm=0.946s total=3.095s\n",
      "PCA  32 | Test Acc=0.5236 | scale=1.127s pca=1.029s svm=0.995s total=3.350s\n",
      "PCA  64 | Test Acc=0.5141 | scale=1.124s pca=1.536s svm=1.094s total=3.999s\n",
      "PCA 128 | Test Acc=0.4926 | scale=1.143s pca=2.525s svm=1.436s total=5.451s\n",
      "PCA 256 | Test Acc=0.4293 | scale=1.122s pca=2.960s svm=2.457s total=7.179s\n"
     ]
    }
   ],
   "source": [
    "PCA_DIMS = [2, 8, 16, 32, 64, 128, 256]  # 원하는 대로 조절\n",
    "\n",
    "hog_pack = train_hog_pca_svm_by_dims(\n",
    "    X_train=X_hog_train,\n",
    "    y_train=y_train_road,\n",
    "    X_test=X_hog_test,\n",
    "    y_test=y_test_road,\n",
    "    pca_dims=PCA_DIMS,\n",
    "    C=10,\n",
    "    gamma=\"scale\"\n",
    ")\n",
    "\n",
    "hog_svm_models = hog_pack[\"hog_svm_models\"]\n",
    "hog_pca_test_features = hog_pack[\"hog_pca_test_features\"]\n",
    "hog_test_acc = hog_pack[\"test_acc\"]\n",
    "hog_time_report = hog_pack[\"time_report\"]\n",
    "\n",
    "print(\"\\n===== HOG+PCA SVM summary =====\")\n",
    "for d in PCA_DIMS:\n",
    "    tr = hog_time_report[d]\n",
    "    print(\n",
    "        f\"PCA {d:>3d} | \"\n",
    "        f\"Test Acc={hog_test_acc[d]:.4f} | \"\n",
    "        f\"scale={tr['scale_sec']:.3f}s pca={tr['pca_sec']:.3f}s svm={tr['svm_fit_sec']:.3f}s total={tr['total_sec']:.3f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c29ac",
   "metadata": {},
   "source": [
    "ALPHA Line regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b343bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LR Fusion per PCA dim =====\n",
      "[PCA dim=  2] alpha_hat(shape)=0.205 | TestAcc=0.7362 | P_fusion_test=(743, 12)\n",
      "[PCA dim=  8] alpha_hat(shape)=0.315 | TestAcc=0.7389 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 16] alpha_hat(shape)=0.374 | TestAcc=0.7631 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 32] alpha_hat(shape)=0.385 | TestAcc=0.7550 | P_fusion_test=(743, 12)\n",
      "[PCA dim= 64] alpha_hat(shape)=0.386 | TestAcc=0.7604 | P_fusion_test=(743, 12)\n",
      "[PCA dim=128] alpha_hat(shape)=0.389 | TestAcc=0.7725 | P_fusion_test=(743, 12)\n",
      "[PCA dim=256] alpha_hat(shape)=0.372 | TestAcc=0.7577 | P_fusion_test=(743, 12)\n",
      "\n",
      "===== Summary =====\n",
      "dim=  2 | alpha_hat=0.205 | acc=0.7362 | P_fusion=(743, 12)\n",
      "dim=  8 | alpha_hat=0.315 | acc=0.7389 | P_fusion=(743, 12)\n",
      "dim= 16 | alpha_hat=0.374 | acc=0.7631 | P_fusion=(743, 12)\n",
      "dim= 32 | alpha_hat=0.385 | acc=0.7550 | P_fusion=(743, 12)\n",
      "dim= 64 | alpha_hat=0.386 | acc=0.7604 | P_fusion=(743, 12)\n",
      "dim=128 | alpha_hat=0.389 | acc=0.7725 | P_fusion=(743, 12)\n",
      "dim=256 | alpha_hat=0.372 | acc=0.7577 | P_fusion=(743, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =========================\n",
    "# 입력 전제(이미 있어야 함)\n",
    "# =========================\n",
    "# PCA_DIMS: list[int]\n",
    "# hog_svm_models: dict[dim -> SVC(probability=True)]\n",
    "# hog_pca_test_features: dict[dim -> np.ndarray (N_test, dim)]\n",
    "# P_color_test: np.ndarray (N_test, K)\n",
    "# y_test_road: np.ndarray (N_test,)\n",
    "# eval_accuracy: 함수(없으면 accuracy_score로 대체 가능)\n",
    "\n",
    "fusion_lr_models = {}      # dim -> LogisticRegression\n",
    "fusion_alpha = {}          # dim -> float (shape vs color 요약 alpha)\n",
    "P_fusion_by_dim = {}       # dim -> np.ndarray (N_test, K)\n",
    "fusion_acc = {}            # dim -> float\n",
    "\n",
    "K = P_color_test.shape[1]\n",
    "\n",
    "print(\"===== LR Fusion per PCA dim =====\")\n",
    "\n",
    "for d in PCA_DIMS:\n",
    "    # 1) HOG 확률 (N_test, K)\n",
    "    P_shape_test = hog_svm_models[d].predict_proba(hog_pca_test_features[d])\n",
    "\n",
    "    # shape 체크\n",
    "    assert P_shape_test.shape == P_color_test.shape, (\n",
    "        f\"[dim={d}] P_shape_test {P_shape_test.shape} vs P_color_test {P_color_test.shape} mismatch\"\n",
    "    )\n",
    "\n",
    "    # 2) fusion 입력 (N_test, 2K)\n",
    "    X_fuse = np.hstack([P_shape_test, P_color_test])\n",
    "\n",
    "    # 3) 회귀(로지스틱)로 fusion 학습 (요구대로 test 라벨 사용)\n",
    "    lr = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000\n",
    "    )\n",
    "\n",
    "    lr.fit(X_fuse, y_test_road)\n",
    "\n",
    "    # 4) fusion 확률 출력 (N_test, K)\n",
    "    P_fusion_test = lr.predict_proba(X_fuse)\n",
    "\n",
    "    # 5) 정확도(참고)\n",
    "    y_pred = np.argmax(P_fusion_test, axis=1).astype(np.int64)\n",
    "    acc = eval_accuracy(y_test_road, y_pred)\n",
    "\n",
    "    # 6) \"alpha(형태 비중)\" 요약값 계산\n",
    "    # lr.coef_ shape: (K, 2K)\n",
    "    W = lr.coef_\n",
    "    w_shape = np.mean(np.abs(W[:, :K]))\n",
    "    w_color = np.mean(np.abs(W[:, K:]))\n",
    "\n",
    "    alpha_hat = float(w_shape / (w_shape + w_color + 1e-12))  # 0~1, 형태 영향 비중\n",
    "\n",
    "    # 저장\n",
    "    fusion_lr_models[d] = lr\n",
    "    fusion_alpha[d] = alpha_hat\n",
    "    P_fusion_by_dim[d] = P_fusion_test\n",
    "    fusion_acc[d] = float(acc)\n",
    "\n",
    "    # 출력\n",
    "    print(f\"[PCA dim={d:>3d}] alpha_hat(shape)={alpha_hat:.3f} | TestAcc={acc:.4f} | P_fusion_test={P_fusion_test.shape}\")\n",
    "\n",
    "# dim별 요약\n",
    "print(\"\\n===== Summary =====\")\n",
    "for d in PCA_DIMS:\n",
    "    print(f\"dim={d:>3d} | alpha_hat={fusion_alpha[d]:.3f} | acc={fusion_acc[d]:.4f} | P_fusion={P_fusion_by_dim[d].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a17cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (LR-Fusion, PCA=128):\n",
      " [[51  1  0  0  5  0  0  0  1  2  2  0]\n",
      " [ 2 35  0  1  3  0  0  0  0  0  1  1]\n",
      " [ 0  0 41  1  2  1  0  1  0  1  0 11]\n",
      " [ 1  0  0 51 10  2  0  0  2  1  2  3]\n",
      " [ 1  1  3  8 71  2  0  0  2  3  5  4]\n",
      " [ 0  1  2  0  3 54  0  1  0  1  2  2]\n",
      " [ 0  1  1  2  0  0 21  1  0  0  0  0]\n",
      " [ 1  2  1  2  1  1  0 26  0  1  1  2]\n",
      " [ 0  2  0  0  3  1  0  1 48  3  0  1]\n",
      " [ 1  0  0  2  8  2  0  1  2 63  0  0]\n",
      " [ 0  0  0  1  8  2  0  0  1  2 28  1]\n",
      " [ 1  0  1  1  8  1  0  0  0  0  0 85]]\n",
      "\n",
      "Classification Report (LR-Fusion, PCA=128):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8793    0.8226    0.8500        62\n",
      "           1     0.8140    0.8140    0.8140        43\n",
      "           2     0.8367    0.7069    0.7664        58\n",
      "           3     0.7391    0.7083    0.7234        72\n",
      "           4     0.5820    0.7100    0.6396       100\n",
      "           5     0.8182    0.8182    0.8182        66\n",
      "           6     1.0000    0.8077    0.8936        26\n",
      "           7     0.8387    0.6842    0.7536        38\n",
      "           8     0.8571    0.8136    0.8348        59\n",
      "           9     0.8182    0.7975    0.8077        79\n",
      "          10     0.6829    0.6512    0.6667        43\n",
      "          11     0.7727    0.8763    0.8213        97\n",
      "\n",
      "    accuracy                         0.7725       743\n",
      "   macro avg     0.8032    0.7675    0.7824       743\n",
      "weighted avg     0.7818    0.7725    0.7745       743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_dim = max(fusion_acc, key=fusion_acc.get)\n",
    "\n",
    "y_pred_best = np.argmax(P_fusion_by_dim[best_dim], axis=1)\n",
    "\n",
    "cm = eval_confusion(y_test_road, y_pred_best)\n",
    "print(f\"Confusion Matrix (LR-Fusion, PCA={best_dim}):\\n\", cm)\n",
    "\n",
    "print(f\"\\nClassification Report (LR-Fusion, PCA={best_dim}):\\n\")\n",
    "print(eval_report(y_test_road, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ada0e",
   "metadata": {},
   "source": [
    "models save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9908ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved with best_dim = 128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# best_dim 기준 모델 선택\n",
    "# =========================\n",
    "best_dim = best_dim   # 이미 위에서 계산된 값 사용\n",
    "\n",
    "hog_scaler = hog_pack[\"hog_pca_models\"][best_dim][0]\n",
    "hog_pca    = hog_pack[\"hog_pca_models\"][best_dim][1]\n",
    "hog_svm    = hog_pack[\"hog_svm_models\"][best_dim]\n",
    "\n",
    "# LR-fusion 모델 (있다면)\n",
    "best_fusion_lr = fusion_lr_models[best_dim]\n",
    "\n",
    "# =========================\n",
    "# 모델 저장\n",
    "# =========================\n",
    "joblib.dump(hog_svm,        f\"{MODEL_DIR}/hog_svm_dim{best_dim}.pkl\")\n",
    "joblib.dump(hog_pca,        f\"{MODEL_DIR}/hog_pca_dim{best_dim}.pkl\")\n",
    "joblib.dump(hog_scaler,     f\"{MODEL_DIR}/hog_scaler_dim{best_dim}.pkl\")\n",
    "\n",
    "joblib.dump(color_svm,      f\"{MODEL_DIR}/color_svm.pkl\")\n",
    "joblib.dump(best_fusion_lr, f\"{MODEL_DIR}/fusion_lr_dim{best_dim}.pkl\")\n",
    "\n",
    "joblib.dump(road_label_map, f\"{MODEL_DIR}/road_label_map.pkl\")\n",
    "\n",
    "print(\"Models saved with best_dim =\", best_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05036adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_knn_models.py\n",
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_detail_models.py\n",
      "new signature: (X_hog_train, X_color_train, training_road_label, training_detail, training_x, training_y, out_dir, hog_pca_dim=128, n_neighbors=7, detail_roads={'donhwamunro_11_da', 'donhwamunro_11_na', 'donhwamunro_11_ga', 'suporo_28'}, min_samples=10, training_paths=None, feature_tag='full')\n"
     ]
    }
   ],
   "source": [
    "import importlib, inspect\n",
    "import fpl_knn_models\n",
    "import fpl_detail_models\n",
    "\n",
    "print(\"loaded from:\", fpl_knn_models.__file__)\n",
    "importlib.reload(fpl_knn_models)\n",
    "print(\"loaded from:\", fpl_detail_models.__file__)\n",
    "importlib.reload(fpl_detail_models)\n",
    "\n",
    "print(\"new signature:\", inspect.signature(fpl_knn_models.train_and_save_knn_models))\n",
    "\n",
    "# ✅ 이 줄이 중요: 로컬 이름을 '새 함수'로 다시 바인딩\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "457b13cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] detail models road=donhwamunro_11_da | classes=['A', 'B', 'C'] | n=177 | pca=128\n",
      "[SAVED] detail models road=donhwamunro_11_ga | classes=['A', 'B', 'C'] | n=213 | pca=128\n",
      "[SAVED] detail models road=donhwamunro_11_na | classes=['A', 'B', 'C', 'D'] | n=300 | pca=128\n",
      "[SAVED] detail models road=suporo_28 | classes=['A', 'B', 'C', 'D', 'E'] | n=296 | pca=128\n",
      "[SAVED] KNN(full) road=donhwamunro | n=189\n",
      "[SAVED] KNN(full) road=donhwamunro_11 | n=130\n",
      "[SAVED] KNN(full) road=donhwamunro_11_da | n=177\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_da detail=A | n=90\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_da detail=B | n=49\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_da detail=C | n=38\n",
      "[SAVED] KNN(full) road=donhwamunro_11_ga | n=213\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_ga detail=A | n=46\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_ga detail=B | n=79\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_ga detail=C | n=88\n",
      "[SAVED] KNN(full) road=donhwamunro_11_na | n=300\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_na detail=A | n=67\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_na detail=B | n=126\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_na detail=C | n=55\n",
      "  [SAVED] KNN(full) road=donhwamunro_11_na detail=D | n=52\n",
      "[SAVED] KNN(full) road=samildaero | n=199\n",
      "[SAVED] KNN(full) road=samildaero_26 | n=79\n",
      "[SAVED] KNN(full) road=samildaero_28 | n=114\n",
      "[SAVED] KNN(full) road=samildaero_30 | n=176\n",
      "[SAVED] KNN(full) road=samildaero_32 | n=229\n",
      "[SAVED] KNN(full) road=samildaero_32_ga | n=129\n",
      "[SAVED] KNN(full) road=suporo_28 | n=296\n",
      "  [SAVED] KNN(full) road=suporo_28 detail=A | n=104\n",
      "  [SAVED] KNN(full) road=suporo_28 detail=B | n=60\n",
      "  [SAVED] KNN(full) road=suporo_28 detail=C | n=38\n",
      "  [SAVED] KNN(full) road=suporo_28 detail=D | n=61\n",
      "  [SAVED] KNN(full) road=suporo_28 detail=E | n=33\n",
      "✅ KNN saved under: FPL_models/knn_models_full\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'saved': [('donhwamunro', 'road'),\n",
       "  ('donhwamunro_11', 'road'),\n",
       "  ('donhwamunro_11_da', 'road'),\n",
       "  ('donhwamunro_11_da', 'A'),\n",
       "  ('donhwamunro_11_da', 'B'),\n",
       "  ('donhwamunro_11_da', 'C'),\n",
       "  ('donhwamunro_11_ga', 'road'),\n",
       "  ('donhwamunro_11_ga', 'A'),\n",
       "  ('donhwamunro_11_ga', 'B'),\n",
       "  ('donhwamunro_11_ga', 'C'),\n",
       "  ('donhwamunro_11_na', 'road'),\n",
       "  ('donhwamunro_11_na', 'A'),\n",
       "  ('donhwamunro_11_na', 'B'),\n",
       "  ('donhwamunro_11_na', 'C'),\n",
       "  ('donhwamunro_11_na', 'D'),\n",
       "  ('samildaero', 'road'),\n",
       "  ('samildaero_26', 'road'),\n",
       "  ('samildaero_28', 'road'),\n",
       "  ('samildaero_30', 'road'),\n",
       "  ('samildaero_32', 'road'),\n",
       "  ('samildaero_32_ga', 'road'),\n",
       "  ('suporo_28', 'road'),\n",
       "  ('suporo_28', 'A'),\n",
       "  ('suporo_28', 'B'),\n",
       "  ('suporo_28', 'C'),\n",
       "  ('suporo_28', 'D'),\n",
       "  ('suporo_28', 'E')],\n",
       " 'knn_root': 'FPL_models/knn_models_full',\n",
       " 'pca_dim_actual': 128,\n",
       " 'feature_tag': 'full'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = \"FPL_models\"  \n",
    "ALPHA_FIXED = float(fusion_alpha[best_dim])   # 모든 디테일 도로에 동일 적용\n",
    "PCA_DIM_DETAIL = best_dim                     # 디테일 HOG PCA도 동일 dim 사용(원하면 숫자 고정해도 됨)\n",
    "\n",
    "training_paths = np.array([image_index.get(fn, \"\") for fn in training_filename], dtype=object)\n",
    "# 1) detail 도로들에 대해 detail 분류용 (Color SVM + HOG SVM) 저장\n",
    "detail_pack = train_and_save_detail_models(\n",
    "    X_hog_train=X_hog_train,\n",
    "    X_color_train=X_color_train,\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "\n",
    "    out_dir=MODEL_DIR,                \n",
    "    alpha_shape=ALPHA_FIXED,          \n",
    "    hog_pca_dim=PCA_DIM_DETAIL,       \n",
    "\n",
    "    C=10,\n",
    "    gamma=\"scale\",\n",
    "\n",
    "    min_total_samples=20,             \n",
    "    min_samples_per_detail=8          \n",
    ")\n",
    "\n",
    "detail_pack\n",
    "\n",
    "\n",
    "# 2) 모든 도로명에 대해 KNN(위치 회귀) 저장 + detail 도로는 A/B/...별 KNN 추가 저장\n",
    "train_and_save_knn_models(\n",
    "    X_hog_train=X_hog_train,\n",
    "    X_color_train=X_color_train,\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    training_x=training_x,\n",
    "    training_y=training_y,\n",
    "    out_dir=MODEL_DIR,\n",
    "    hog_pca_dim=best_dim,\n",
    "    n_neighbors=10,\n",
    "    min_samples=10,\n",
    "    training_paths=training_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb94a49",
   "metadata": {},
   "source": [
    "not 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b7475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_color_train: (2231, 124) float32\n"
     ]
    }
   ],
   "source": [
    "# Color (HS hist) - full image\n",
    "X_color_train = extract_color_hs_full(Training_origin_data, h_bins=60, s_bins=64, sizes=None)\n",
    "X_color_test  = extract_color_hs_full(Test_data,            h_bins=60, s_bins=64, sizes=None)\n",
    "\n",
    "print(\"X_color_train:\", X_color_train.shape, X_color_train.dtype)\n",
    "\n",
    "# HOG - full image (추가 resize 없음)\n",
    "X_hog_train = extract_hog_full(\n",
    "    Training_origin_data,\n",
    "    hog_sizes=None,            # 중요: 추가 resize 없음\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    ")\n",
    "X_hog_test = extract_hog_full(\n",
    "    Test_data,\n",
    "    hog_sizes=None,\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    ")\n",
    "\n",
    "print(\"X_hog_train:\", X_hog_train.shape, X_hog_train.dtype)\n",
    "\n",
    "# LBP - full image (추가 resize 없음)\n",
    "X_lbp_train = extract_lbp_full(Training_origin_data, resize=None, P=24, R=3, method=\"uniform\")\n",
    "X_lbp_test  = extract_lbp_full(Test_data,            resize=None, P=24, R=3, method=\"uniform\")\n",
    "\n",
    "print(\"X_lbp_train:\", X_lbp_train.shape, X_lbp_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eeb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_color = StandardScaler()\n",
    "Xc_tr = sc_color.fit_transform(X_color_train)\n",
    "Xc_te = sc_color.transform(X_color_test)\n",
    "\n",
    "Xh_tr, Xh_te = X_hog_train, X_hog_test  \n",
    "\n",
    "sc_lbp = StandardScaler()\n",
    "Xl_tr = sc_lbp.fit_transform(X_lbp_train)\n",
    "Xl_te = sc_lbp.transform(X_lbp_test)\n",
    "\n",
    "print(\"scaled color:\", Xc_tr.shape, \"scaled lbp:\", Xl_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2597a56",
   "metadata": {},
   "source": [
    "model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_color = train_color_svm(Xc_tr, y_train_road, C=10, gamma=\"scale\")\n",
    "svm_lbp   = train_lbp_svm(Xl_tr, y_train_road, C=10, gamma=\"scale\")\n",
    "\n",
    "res_color = eval_svm(svm_color, Xc_tr, y_train_road, Xc_te, y_test_road, name=\"COLOR_SVM\")\n",
    "res_lbp   = eval_svm(svm_lbp,   Xl_tr, y_train_road, Xl_te, y_test_road, name=\"LBP_SVM\")\n",
    "\n",
    "pd.DataFrame([res_color, res_lbp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = [64, 128, 256, 512]   # 필요하면 더 추가/조정\n",
    "hog_result = train_hog_pca_svm_by_dims(\n",
    "    X_hog_train, y_train_road,\n",
    "    X_hog_test,  y_test_road,\n",
    "    pca_dims=pca_dims,\n",
    "    C=10,\n",
    "    gamma=\"scale\",\n",
    ")\n",
    "\n",
    "df_hog = pd.DataFrame({\n",
    "    \"dim\": pca_dims,\n",
    "    \"train_acc\": [hog_result[\"train_acc\"][d] for d in pca_dims],\n",
    "    \"test_acc\":  [hog_result[\"test_acc\"][d]  for d in pca_dims],\n",
    "    \"total_sec\": [hog_result[\"time_report\"][d][\"total_sec\"] for d in pca_dims],\n",
    "}).sort_values(\"test_acc\", ascending=False)\n",
    "\n",
    "df_hog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dim = int(df_hog.iloc[0][\"dim\"])\n",
    "print(\"best_dim:\", best_dim)\n",
    "\n",
    "# best_dim의 (scaler,pca)와 svm\n",
    "hog_scaler, hog_pca = hog_result[\"hog_pca_models\"][best_dim]\n",
    "svm_hog = hog_result[\"hog_svm_models\"][best_dim]\n",
    "\n",
    "Xh_tr = hog_result[\"hog_pca_train_features\"][best_dim]\n",
    "Xh_te = hog_result[\"hog_pca_test_features\"][best_dim]\n",
    "\n",
    "res_hog = eval_svm(svm_hog, Xh_tr, y_train_road, Xh_te, y_test_road, name=f\"HOG_PCA{best_dim}_SVM\")\n",
    "pd.DataFrame([res_hog])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 캘리브레이터 (학습데이터로 fit)\n",
    "cal_color = fit_sigmoid_calibrator(svm_color, Xc_tr, y_train_road, q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95)\n",
    "cal_lbp   = fit_sigmoid_calibrator(svm_lbp,   Xl_tr, y_train_road, q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95)\n",
    "cal_hog   = fit_sigmoid_calibrator(svm_hog,   Xh_tr, y_train_road, q_lo=0.10, q_hi=0.90, p_lo=0.05, p_hi=0.95)\n",
    "\n",
    "# 테스트에서 \"커스텀 확률\" 생성\n",
    "P_color = predict_proba_custom(svm_color, Xc_te, method=\"sigmoid\", calibrator=cal_color, power=1.0)\n",
    "P_lbp   = predict_proba_custom(svm_lbp,   Xl_te, method=\"sigmoid\", calibrator=cal_lbp,   power=1.0)\n",
    "P_hog   = predict_proba_custom(svm_hog,   Xh_te, method=\"sigmoid\", calibrator=cal_hog,   power=1.0)\n",
    "\n",
    "print(P_color.shape, P_lbp.shape, P_hog.shape)\n",
    "print(\"row-sum check:\", P_color[0].sum(), P_lbp[0].sum(), P_hog[0].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51163e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치(원하는대로 조절)\n",
    "w_hog   = 0.6\n",
    "w_color = 0.3\n",
    "w_lbp   = 0.1\n",
    "\n",
    "P_final = fuse_probabilities([P_hog, P_color, P_lbp], weights=[w_hog, w_color, w_lbp])\n",
    "\n",
    "final_acc, final_pred = evaluate_fusion(P_final, y_test_road)\n",
    "print(\"Final Fusion Accuracy:\", final_acc)\n",
    "\n",
    "# 개별 모델도 확률 기반 argmax로 accuracy 찍어보기(참고)\n",
    "acc_hog, _   = evaluate_fusion(P_hog, y_test_road)\n",
    "acc_color, _ = evaluate_fusion(P_color, y_test_road)\n",
    "acc_lbp, _   = evaluate_fusion(P_lbp, y_test_road)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"model\":\"HOG(sigmoid)\",   \"acc\":acc_hog},\n",
    "    {\"model\":\"COLOR(sigmoid)\", \"acc\":acc_color},\n",
    "    {\"model\":\"LBP(sigmoid)\",   \"acc\":acc_lbp},\n",
    "    {\"model\":\"FUSION\",         \"acc\":final_acc},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66361e5",
   "metadata": {},
   "source": [
    "models_mark2 save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5568f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "from datetime import datetime\n",
    "\n",
    "MODEL_DIR = \"FPL_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "best_dim = best_dim  # 이미 계산된 값\n",
    "\n",
    "# (HOG road 분류) pack에서 best_dim 모델 꺼내기\n",
    "hog_scaler = hog_pack[\"hog_pca_models\"][best_dim][0]\n",
    "hog_pca    = hog_pack[\"hog_pca_models\"][best_dim][1]\n",
    "hog_svm    = hog_pack[\"hog_svm_models\"][best_dim]\n",
    "\n",
    "best_fusion_lr = fusion_lr_models[best_dim] if \"fusion_lr_models\" in globals() else None\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ✅ full feature 세팅을 tag에 박아두면 나중에 헷갈릴 일 없음\n",
    "tag = f\"FULL_HS60x64_HOGori12_LBP24R3_dim{best_dim}_{ts}\"\n",
    "\n",
    "# ===== road models =====\n",
    "joblib.dump(hog_svm,    f\"{MODEL_DIR}/hog_svm_{tag}.pkl\")\n",
    "joblib.dump(hog_pca,    f\"{MODEL_DIR}/hog_pca_{tag}.pkl\")\n",
    "joblib.dump(hog_scaler, f\"{MODEL_DIR}/hog_scaler_{tag}.pkl\")\n",
    "\n",
    "joblib.dump(color_svm,  f\"{MODEL_DIR}/color_svm_{tag}.pkl\")  # Color SVM은 Xc_tr로 학습했다고 가정\n",
    "\n",
    "# ===== LBP SVM (있으면) =====\n",
    "if \"lbp_svm\" in globals():\n",
    "    joblib.dump(lbp_svm, f\"{MODEL_DIR}/lbp_svm_{tag}.pkl\")   # LBP SVM은 Xl_tr로 학습했다고 가정\n",
    "\n",
    "# ===== calibrator (있으면) =====\n",
    "if \"cal_hog\" in globals():\n",
    "    joblib.dump(cal_hog, f\"{MODEL_DIR}/cal_hog_{tag}.pkl\")\n",
    "if \"cal_color\" in globals():\n",
    "    joblib.dump(cal_color, f\"{MODEL_DIR}/cal_color_{tag}.pkl\")\n",
    "if \"cal_lbp\" in globals():\n",
    "    joblib.dump(cal_lbp, f\"{MODEL_DIR}/cal_lbp_{tag}.pkl\")\n",
    "\n",
    "# ✅ 여기! 지금 너가 만든 scaler 변수명으로 저장\n",
    "# (app에서 읽는 파일명과 호환되게 유지)\n",
    "joblib.dump(sc_color, f\"{MODEL_DIR}/color_scaler_{tag}.pkl\")\n",
    "joblib.dump(sc_lbp,   f\"{MODEL_DIR}/lbp_scaler_{tag}.pkl\")\n",
    "\n",
    "# ===== fusion weights (있으면) =====\n",
    "if all(v in globals() for v in [\"w_hog\", \"w_color\", \"w_lbp\"]):\n",
    "    joblib.dump({\"w_hog\": w_hog, \"w_color\": w_color, \"w_lbp\": w_lbp},\n",
    "                f\"{MODEL_DIR}/fusion_weights_{tag}.pkl\")\n",
    "\n",
    "# ===== LR-fusion (있으면) =====\n",
    "if best_fusion_lr is not None:\n",
    "    joblib.dump(best_fusion_lr, f\"{MODEL_DIR}/fusion_lr_{tag}.pkl\")\n",
    "\n",
    "# ===== label map =====\n",
    "joblib.dump(road_label_map, f\"{MODEL_DIR}/road_label_map_{tag}.pkl\")\n",
    "\n",
    "print(\"Models saved. best_dim =\", best_dim)\n",
    "print(\"Tag =\", tag)\n",
    "print(\"Dir =\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d861983",
   "metadata": {},
   "source": [
    "detail_SVM and kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdab585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: /home/hanseong/vscode/ML_code/FPL/FPL/src/fpl_knn_models.py\n",
      "new signature: (X_hog_train, X_color_train, training_road_label, training_detail, training_x, training_y, out_dir, hog_pca_dim=128, n_neighbors=7, detail_roads={'donhwamunro_11_ga', 'suporo_28', 'donhwamunro_11_da', 'donhwamunro_11_na'}, min_samples=10, training_paths=None)\n"
     ]
    }
   ],
   "source": [
    "import importlib, inspect\n",
    "import fpl_knn_models\n",
    "import fpl_detail_models\n",
    "\n",
    "print(\"loaded from:\", fpl_knn_models.__file__)\n",
    "importlib.reload(fpl_knn_models)\n",
    "print(\"loaded from:\", fpl_detail_models.__file__)\n",
    "importlib.reload(fpl_detail_models)\n",
    "\n",
    "print(\"new signature:\", inspect.signature(fpl_knn_models.train_and_save_knn_models))\n",
    "\n",
    "# ✅ 이 줄이 중요: 로컬 이름을 '새 함수'로 다시 바인딩\n",
    "train_and_save_knn_models = fpl_knn_models.train_and_save_knn_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"FPL_models\" \n",
    "ALPHA_FIXED = float(fusion_alpha[best_dim]) \n",
    "# 모든 디테일 도로에 동일 적용 PCA_DIM_DETAIL = best_dim \n",
    "# # 디테일 HOG PCA도 동일 dim 사용(원하면 숫자 고정해도 됨)\n",
    "\n",
    "# X_hog_full_train, X_color_full_train  (N, D) 형태\n",
    "\n",
    "detail_pack = train_and_save_detail_models(\n",
    "    X_hog_train=Xh_tr,\n",
    "    X_color_train=Xc_tr,   # ✅ 스케일된 color\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    out_dir=MODEL_DIR,\n",
    "    alpha_shape=ALPHA_FIXED,\n",
    "    hog_pca_dim=best_dim,\n",
    "    C=10, gamma=\"scale\",\n",
    "    min_total_samples=20,\n",
    "    min_samples_per_detail=8,\n",
    "    feature_tag=\"full\",    # (내가 전에 준 버전 기준)\n",
    ")\n",
    "\n",
    "knn_pack = train_and_save_knn_models(\n",
    "    X_hog_train=Xh_tr,\n",
    "    X_color_train=Xc_tr,   # ✅ 스케일된 color\n",
    "    training_road_label=training_road_label,\n",
    "    training_detail=training_detail,\n",
    "    training_x=training_x,\n",
    "    training_y=training_y,\n",
    "    out_dir=MODEL_DIR,\n",
    "    hog_pca_dim=best_dim,\n",
    "    n_neighbors=10,\n",
    "    min_samples=10,\n",
    "    training_paths=training_paths,\n",
    "    feature_tag=\"full\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef338bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def euclid_dist(a, b):\n",
    "    # a,b: (N,2)\n",
    "    return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "\n",
    "def clean_detail_arr(detail_arr):\n",
    "    # detail이 NaN/None/\"0\" 섞여있어도 안전하게 문자열로\n",
    "    out = []\n",
    "    for d in detail_arr:\n",
    "        s = str(d).strip()\n",
    "        if s.lower() in (\"nan\", \"none\", \"\"):\n",
    "            s = \"0\"\n",
    "        out.append(s)\n",
    "    return np.array(out, dtype=object)\n",
    "\n",
    "KNN_ROOT = os.path.join(MODEL_DIR, \"knn_models\")\n",
    "\n",
    "knn_scaler = joblib.load(os.path.join(KNN_ROOT, \"knn_hog_scaler_pca128.pkl\"))\n",
    "knn_pca    = joblib.load(os.path.join(KNN_ROOT, \"knn_hog_pca_pca128.pkl\"))\n",
    "\n",
    "def make_knn_Z(X_hog, X_color):\n",
    "    Xh_p = knn_pca.transform(knn_scaler.transform(X_hog))\n",
    "    return np.hstack([Xh_p, X_color])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b80a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples: 97\n",
      "\n",
      "=== Detail SVM Fusion Eval | road=suporo_28 | alpha=0.389 ===\n",
      "Accuracy: 0.7835051546391752\n",
      "\n",
      "Confusion:\n",
      " [[30  0  1  0  4]\n",
      " [ 3 15  1  1  0]\n",
      " [ 1  1 10  0  0]\n",
      " [ 2  1  1 15  1]\n",
      " [ 3  0  0  1  6]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.77      0.86      0.81        35\n",
      "           B       0.88      0.75      0.81        20\n",
      "           C       0.77      0.83      0.80        12\n",
      "           D       0.88      0.75      0.81        20\n",
      "           E       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.78        97\n",
      "   macro avg       0.77      0.76      0.76        97\n",
      "weighted avg       0.79      0.78      0.78        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"FPL_models\"\n",
    "ALPHA_FIXED = 0.389  # 네가 쓰는 고정 alpha (원하면 바꿔도 됨)\n",
    "\n",
    "ROAD = \"suporo_28\"   # 여기만 바꿔서 도로별로 평가 가능\n",
    "\n",
    "dt = clean_detail_arr(test_detail)\n",
    "\n",
    "# test 중에서 해당 road + detail 있는 샘플만\n",
    "idx = np.where((test_road_label == ROAD) & (dt != \"0\"))[0]\n",
    "print(\"Eval samples:\", len(idx))\n",
    "\n",
    "if len(idx) == 0:\n",
    "    print(\"해당 road/detail 샘플이 test에 없음\")\n",
    "else:\n",
    "    base = os.path.join(MODEL_DIR, \"detail_models\", ROAD)\n",
    "\n",
    "    hog_svm    = joblib.load(os.path.join(base, \"hog_svm.pkl\"))\n",
    "    hog_pca    = joblib.load(os.path.join(base, \"hog_pca.pkl\"))\n",
    "    hog_scaler = joblib.load(os.path.join(base, \"hog_scaler.pkl\"))\n",
    "    color_svm  = joblib.load(os.path.join(base, \"color_svm.pkl\"))\n",
    "\n",
    "    detail_map = joblib.load(os.path.join(base, \"detail_label_map.pkl\"))\n",
    "    inv_map = {v:k for k,v in detail_map.items()}\n",
    "\n",
    "    Xh = X_hog_test[idx]\n",
    "    Xc = X_color_test[idx]\n",
    "    y_true = dt[idx]  # 'A','B','C'...\n",
    "\n",
    "    # HOG pipeline\n",
    "    Xh_s = hog_scaler.transform(Xh)\n",
    "    Xh_p = hog_pca.transform(Xh_s)\n",
    "\n",
    "    # prob\n",
    "    P_shape = hog_svm.predict_proba(Xh_p)\n",
    "    P_color = color_svm.predict_proba(Xc)\n",
    "\n",
    "    # fusion\n",
    "    P_fuse = ALPHA_FIXED * P_shape + (1 - ALPHA_FIXED) * P_color\n",
    "\n",
    "    y_pred_idx = np.argmax(P_fuse, axis=1)\n",
    "    y_pred = np.array([inv_map[i] for i in y_pred_idx], dtype=object)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n=== Detail SVM Fusion Eval | road={ROAD} | alpha={ALPHA_FIXED} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nConfusion:\\n\", confusion_matrix(y_true, y_pred, labels=sorted(list(set(y_true)))))\n",
    "    print(\"\\nReport:\\n\", classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6594ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detail SVM Fusion Summary ===\n",
      "donhwamunro_11_ga: n=72 acc=0.7500\n",
      "donhwamunro_11_na: n=100 acc=0.8100\n",
      "donhwamunro_11_da: n=58 acc=0.8793\n",
      "suporo_28: n=97 acc=0.7835\n"
     ]
    }
   ],
   "source": [
    "DETAIL_ROADS = [\"donhwamunro_11_ga\", \"donhwamunro_11_na\", \"donhwamunro_11_da\", \"suporo_28\"]\n",
    "\n",
    "dt = clean_detail_arr(test_detail)\n",
    "\n",
    "summary = {}\n",
    "for ROAD in DETAIL_ROADS:\n",
    "    idx = np.where((test_road_label == ROAD) & (dt != \"0\"))[0]\n",
    "    if len(idx) == 0:\n",
    "        summary[ROAD] = None\n",
    "        continue\n",
    "\n",
    "    base = os.path.join(MODEL_DIR, \"detail_models\", ROAD)\n",
    "\n",
    "    hog_svm    = joblib.load(os.path.join(base, \"hog_svm.pkl\"))\n",
    "    hog_pca    = joblib.load(os.path.join(base, \"hog_pca.pkl\"))\n",
    "    hog_scaler = joblib.load(os.path.join(base, \"hog_scaler.pkl\"))\n",
    "    color_svm  = joblib.load(os.path.join(base, \"color_svm.pkl\"))\n",
    "\n",
    "    detail_map = joblib.load(os.path.join(base, \"detail_label_map.pkl\"))\n",
    "    inv_map = {v:k for k,v in detail_map.items()}\n",
    "\n",
    "    Xh = X_hog_test[idx]\n",
    "    Xc = X_color_test[idx]\n",
    "    y_true = dt[idx]\n",
    "\n",
    "    Xh_p = hog_pca.transform(hog_scaler.transform(Xh))\n",
    "    P_shape = hog_svm.predict_proba(Xh_p)\n",
    "    P_color = color_svm.predict_proba(Xc)\n",
    "    P_fuse  = ALPHA_FIXED * P_shape + (1 - ALPHA_FIXED) * P_color\n",
    "\n",
    "    y_pred = np.array([inv_map[i] for i in np.argmax(P_fuse, axis=1)], dtype=object)\n",
    "\n",
    "    summary[ROAD] = {\n",
    "        \"n\": len(idx),\n",
    "        \"acc\": float(accuracy_score(y_true, y_pred))\n",
    "    }\n",
    "\n",
    "print(\"=== Detail SVM Fusion Summary ===\")\n",
    "for r, v in summary.items():\n",
    "    if v is None:\n",
    "        print(f\"{r}: (no samples)\")\n",
    "    else:\n",
    "        print(f\"{r}: n={v['n']} acc={v['acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples: 100\n",
      "\n",
      "=== Road KNN Eval | road=donhwamunro_11_na ===\n",
      "Mean dist  : 1.3513006679775241\n",
      "Median dist: 1.1110861492932425\n",
      "90% dist   : 2.5679790074481845\n"
     ]
    }
   ],
   "source": [
    "ROAD = \"donhwamunro_11_na\"   # 원하는 도로로 바꿔\n",
    "\n",
    "# 좌표 있는 샘플만 평가\n",
    "xy = np.stack([test_x, test_y], axis=1)\n",
    "valid = np.isfinite(xy).all(axis=1)\n",
    "\n",
    "idx = np.where((test_road_label == ROAD) & valid)[0]\n",
    "print(\"Eval samples:\", len(idx))\n",
    "\n",
    "if len(idx) == 0:\n",
    "    print(\"해당 road에 좌표 있는 test 샘플이 없음\")\n",
    "else:\n",
    "    Z = make_knn_Z(X_hog_test[idx], X_color_test[idx])\n",
    "    gt_xy = xy[idx]\n",
    "\n",
    "    knn_road = joblib.load(os.path.join(KNN_ROOT, ROAD, \"knn_road.pkl\"))\n",
    "    pred_xy = knn_road.predict(Z)\n",
    "\n",
    "    dist = euclid_dist(pred_xy, gt_xy)\n",
    "\n",
    "    print(f\"\\n=== Road KNN Eval | road={ROAD} ===\")\n",
    "    print(\"Mean dist  :\", float(dist.mean()))\n",
    "    print(\"Median dist:\", float(np.median(dist)))\n",
    "    print(\"90% dist   :\", float(np.percentile(dist, 90)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec62a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_ROOT: FPL_models/knn_models\n",
      "valid xy: 743 / 743\n",
      "Z_test shape: (743, 686)\n",
      "used scaler: FPL_models/knn_models/knn_hog_scaler_pca128.pkl\n",
      "used pca   : FPL_models/knn_models/knn_hog_pca_pca128.pkl\n",
      "\n",
      "=== Road KNN Distance Report (sorted by mean) ===\n",
      "samildaero      | n=  66 | mean=0.000 | median=0.000 | p90=0.000\n",
      "samildaero_32   | n=  79 | mean=0.000 | median=0.000 | p90=0.000\n",
      "samildaero_26   | n=  26 | mean=0.211 | median=0.156 | p90=0.405\n",
      "samildaero_28   | n=  38 | mean=0.607 | median=0.659 | p90=1.108\n",
      "samildaero_32_ga | n=  43 | mean=0.614 | median=0.598 | p90=1.211\n",
      "donhwamunro_11  | n=  43 | mean=1.026 | median=0.988 | p90=1.880\n",
      "donhwamunro_11_da | n=  58 | mean=1.080 | median=1.013 | p90=1.892\n",
      "suporo_28       | n=  97 | mean=1.122 | median=1.137 | p90=1.594\n",
      "donhwamunro     | n=  62 | mean=1.142 | median=1.192 | p90=1.803\n",
      "samildaero_30   | n=  59 | mean=1.258 | median=1.229 | p90=2.241\n",
      "donhwamunro_11_na | n= 100 | mean=1.351 | median=1.111 | p90=2.568\n",
      "donhwamunro_11_ga | n=  72 | mean=1.524 | median=1.564 | p90=2.683\n",
      "\n",
      "=== Detail KNN Distance Report (sorted by mean) ===\n",
      "suporo_28       | detail=E | n=  10 | mean=0.000 | median=0.000 | p90=0.000 | Δmean_vs_road=+1.572 | Δmed_vs_road=+1.587\n",
      "donhwamunro_11_na | detail=C | n=  18 | mean=0.000 | median=0.000 | p90=0.000 | Δmean_vs_road=+1.196 | Δmed_vs_road=+1.116\n",
      "donhwamunro_11_na | detail=D | n=  17 | mean=0.308 | median=0.196 | p90=0.622 | Δmean_vs_road=+1.640 | Δmed_vs_road=+1.865\n",
      "donhwamunro_11_ga | detail=C | n=  29 | mean=0.343 | median=0.101 | p90=1.000 | Δmean_vs_road=+1.186 | Δmed_vs_road=+1.535\n",
      "donhwamunro_11_da | detail=C | n=  12 | mean=0.352 | median=0.136 | p90=0.797 | Δmean_vs_road=+1.480 | Δmed_vs_road=+1.689\n",
      "suporo_28       | detail=C | n=  12 | mean=0.386 | median=0.378 | p90=0.684 | Δmean_vs_road=+0.213 | Δmed_vs_road=+0.147\n",
      "donhwamunro_11_da | detail=A | n=  30 | mean=0.388 | median=0.390 | p90=0.599 | Δmean_vs_road=+0.405 | Δmed_vs_road=+0.289\n",
      "donhwamunro_11_ga | detail=A | n=  16 | mean=0.435 | median=0.381 | p90=0.655 | Δmean_vs_road=+2.044 | Δmed_vs_road=+2.166\n",
      "donhwamunro_11_da | detail=B | n=  16 | mean=0.441 | median=0.334 | p90=0.996 | Δmean_vs_road=+0.613 | Δmed_vs_road=+0.679\n",
      "suporo_28       | detail=D | n=  20 | mean=0.449 | median=0.450 | p90=0.633 | Δmean_vs_road=+0.524 | Δmed_vs_road=+0.577\n",
      "donhwamunro_11_na | detail=B | n=  42 | mean=0.451 | median=0.487 | p90=0.698 | Δmean_vs_road=+0.427 | Δmed_vs_road=+0.422\n",
      "suporo_28       | detail=B | n=  20 | mean=0.526 | median=0.500 | p90=0.664 | Δmean_vs_road=+0.630 | Δmed_vs_road=+0.658\n",
      "donhwamunro_11_ga | detail=B | n=  27 | mean=0.693 | median=0.745 | p90=1.230 | Δmean_vs_road=+0.259 | Δmed_vs_road=-0.050\n",
      "donhwamunro_11_na | detail=A | n=  23 | mean=0.737 | median=0.499 | p90=1.458 | Δmean_vs_road=+1.159 | Δmed_vs_road=+1.271\n",
      "suporo_28       | detail=A | n=  35 | mean=0.905 | median=1.030 | p90=1.430 | Δmean_vs_road=+0.332 | Δmed_vs_road=+0.227\n",
      "\n",
      "=== Summary ===\n",
      "roads evaluated : 12\n",
      "details evaluated: 15\n"
     ]
    }
   ],
   "source": [
    "# ===== 전제: 이미 존재해야 하는 변수들 =====\n",
    "# KNN_ROOT: 예) \"FPL_models/knn_models\"\n",
    "# X_hog_test, X_color_test\n",
    "# test_road_label, test_detail\n",
    "# test_x, test_y\n",
    "\n",
    "def _clean_detail_arr(arr):\n",
    "    out = []\n",
    "    for d in arr:\n",
    "        if d is None:\n",
    "            out.append(\"0\")\n",
    "            continue\n",
    "        s = str(d).strip()\n",
    "        if s.lower() in (\"nan\", \"none\", \"\"):\n",
    "            out.append(\"0\")\n",
    "        else:\n",
    "            out.append(s)\n",
    "    return np.array(out, dtype=object)\n",
    "\n",
    "def _euclid_dist(pred_xy, gt_xy):\n",
    "    return np.sqrt(np.sum((pred_xy - gt_xy) ** 2, axis=1))\n",
    "\n",
    "def _make_knn_Z_from_saved_scaler_pca(X_hog, X_color, knn_root):\n",
    "    # knn_root 안에 저장된 scaler/pca 자동 탐색\n",
    "    scaler_path = None\n",
    "    pca_path = None\n",
    "    for fn in os.listdir(knn_root):\n",
    "        if fn.startswith(\"knn_hog_scaler_\") and fn.endswith(\".pkl\"):\n",
    "            scaler_path = os.path.join(knn_root, fn)\n",
    "        if fn.startswith(\"knn_hog_pca_\") and fn.endswith(\".pkl\"):\n",
    "            pca_path = os.path.join(knn_root, fn)\n",
    "\n",
    "    if scaler_path is None or pca_path is None:\n",
    "        raise FileNotFoundError(\"Cannot find knn_hog_scaler_*.pkl or knn_hog_pca_*.pkl under \" + knn_root)\n",
    "\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    pca = joblib.load(pca_path)\n",
    "\n",
    "    Xh_s = scaler.transform(X_hog)\n",
    "    Xh_p = pca.transform(Xh_s)\n",
    "    Z = np.hstack([Xh_p, X_color])\n",
    "    return Z, scaler_path, pca_path\n",
    "\n",
    "\n",
    "# =========================\n",
    "# (1) test 준비\n",
    "# =========================\n",
    "dt = _clean_detail_arr(test_detail)\n",
    "\n",
    "xy = np.stack([test_x, test_y], axis=1).astype(np.float32)\n",
    "valid = np.isfinite(xy).all(axis=1)\n",
    "\n",
    "print(\"KNN_ROOT:\", KNN_ROOT)\n",
    "print(\"valid xy:\", int(valid.sum()), \"/\", len(valid))\n",
    "\n",
    "# =========================\n",
    "# (2) KNN 공통 feature 만들기 (저장된 scaler/pca 사용)\n",
    "# =========================\n",
    "Z_test, used_scaler_path, used_pca_path = _make_knn_Z_from_saved_scaler_pca(\n",
    "    X_hog_test, X_color_test, KNN_ROOT\n",
    ")\n",
    "print(\"Z_test shape:\", Z_test.shape)\n",
    "print(\"used scaler:\", used_scaler_path)\n",
    "print(\"used pca   :\", used_pca_path)\n",
    "\n",
    "# =========================\n",
    "# (3) 전체 road/detail 모델 스캔\n",
    "# =========================\n",
    "roads = sorted([d for d in os.listdir(KNN_ROOT) if os.path.isdir(os.path.join(KNN_ROOT, d))])\n",
    "\n",
    "road_rows = []\n",
    "detail_rows = []\n",
    "\n",
    "for road in roads:\n",
    "    road_dir = os.path.join(KNN_ROOT, road)\n",
    "    road_model_path = os.path.join(road_dir, \"knn_road.pkl\")\n",
    "    if not os.path.exists(road_model_path):\n",
    "        continue\n",
    "\n",
    "    # ---- road 모델 평가 (해당 road test subset) ----\n",
    "    idx_r = np.where((test_road_label == road) & valid)[0]\n",
    "    if len(idx_r) > 0:\n",
    "        knn_road = joblib.load(road_model_path)\n",
    "        pred_r = knn_road.predict(Z_test[idx_r])\n",
    "        dist_r = _euclid_dist(pred_r, xy[idx_r])\n",
    "\n",
    "        road_rows.append({\n",
    "            \"road\": road,\n",
    "            \"n\": int(len(idx_r)),\n",
    "            \"mean\": float(dist_r.mean()),\n",
    "            \"median\": float(np.median(dist_r)),\n",
    "            \"p90\": float(np.percentile(dist_r, 90)),\n",
    "        })\n",
    "\n",
    "    # ---- detail 모델들 평가 ----\n",
    "    # 폴더 내 knn_detail_*.pkl 전부\n",
    "    for fn in sorted(os.listdir(road_dir)):\n",
    "        if not (fn.startswith(\"knn_detail_\") and fn.endswith(\".pkl\")):\n",
    "            continue\n",
    "        det = fn[len(\"knn_detail_\"):-len(\".pkl\")]\n",
    "\n",
    "        idx_d = np.where((test_road_label == road) & (dt == det) & valid)[0]\n",
    "        if len(idx_d) == 0:\n",
    "            continue\n",
    "\n",
    "        knn_det = joblib.load(os.path.join(road_dir, fn))\n",
    "        pred_d = knn_det.predict(Z_test[idx_d])\n",
    "        dist_d = _euclid_dist(pred_d, xy[idx_d])\n",
    "\n",
    "        # 비교용: 같은 subset에서 road knn도 같이 평가해서 개선량 계산\n",
    "        if os.path.exists(road_model_path):\n",
    "            knn_road = joblib.load(road_model_path)\n",
    "            pred_r2 = knn_road.predict(Z_test[idx_d])\n",
    "            dist_r2 = _euclid_dist(pred_r2, xy[idx_d])\n",
    "            mean_improve = float(dist_r2.mean() - dist_d.mean())\n",
    "            med_improve = float(np.median(dist_r2) - np.median(dist_d))\n",
    "        else:\n",
    "            mean_improve = float(\"nan\")\n",
    "            med_improve = float(\"nan\")\n",
    "\n",
    "        detail_rows.append({\n",
    "            \"road\": road,\n",
    "            \"detail\": det,\n",
    "            \"n\": int(len(idx_d)),\n",
    "            \"mean\": float(dist_d.mean()),\n",
    "            \"median\": float(np.median(dist_d)),\n",
    "            \"p90\": float(np.percentile(dist_d, 90)),\n",
    "            \"mean_improve_vs_road\": mean_improve,\n",
    "            \"median_improve_vs_road\": med_improve,\n",
    "        })\n",
    "\n",
    "# =========================\n",
    "# (4) 출력\n",
    "# =========================\n",
    "print(\"\\n=== Road KNN Distance Report (sorted by mean) ===\")\n",
    "road_rows_sorted = sorted(road_rows, key=lambda x: x[\"mean\"])\n",
    "for r in road_rows_sorted:\n",
    "    print(f\"{r['road']:15s} | n={r['n']:4d} | mean={r['mean']:.3f} | median={r['median']:.3f} | p90={r['p90']:.3f}\")\n",
    "\n",
    "print(\"\\n=== Detail KNN Distance Report (sorted by mean) ===\")\n",
    "detail_rows_sorted = sorted(detail_rows, key=lambda x: x[\"mean\"])\n",
    "for r in detail_rows_sorted:\n",
    "    print(\n",
    "        f\"{r['road']:15s} | detail={r['detail']:>1s} | n={r['n']:4d} | \"\n",
    "        f\"mean={r['mean']:.3f} | median={r['median']:.3f} | p90={r['p90']:.3f} | \"\n",
    "        f\"Δmean_vs_road={r['mean_improve_vs_road']:+.3f} | Δmed_vs_road={r['median_improve_vs_road']:+.3f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(\"roads evaluated :\", len(road_rows))\n",
    "print(\"details evaluated:\", len(detail_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5cf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid xy: 743 / 743\n",
      "\n",
      "[ROAD] donhwamunro_11_da\n",
      "  details: ['A', 'B', 'C']\n",
      "    detail=A | valid samples=30\n",
      "    detail=B | valid samples=16\n",
      "    detail=C | valid samples=12\n",
      "\n",
      "[ROAD] donhwamunro_11_ga\n",
      "  details: ['A', 'B', 'C']\n",
      "    detail=A | valid samples=16\n",
      "    detail=B | valid samples=27\n",
      "    detail=C | valid samples=29\n",
      "\n",
      "[ROAD] donhwamunro_11_na\n",
      "  details: ['A', 'B', 'C', 'D']\n",
      "    detail=A | valid samples=23\n",
      "    detail=B | valid samples=42\n",
      "    detail=C | valid samples=18\n",
      "    detail=D | valid samples=17\n",
      "\n",
      "[ROAD] suporo_28\n",
      "  details: ['A', 'B', 'C', 'D', 'E']\n",
      "    detail=A | valid samples=35\n",
      "    detail=B | valid samples=20\n",
      "    detail=C | valid samples=12\n",
      "    detail=D | valid samples=20\n",
      "    detail=E | valid samples=10\n",
      "\n",
      "=== detail_report rows === 15\n"
     ]
    }
   ],
   "source": [
    "DETAIL_ROADS = [\n",
    "    \"donhwamunro_11_da\",\n",
    "    \"donhwamunro_11_ga\",\n",
    "    \"donhwamunro_11_na\",\n",
    "    \"suporo_28\",\n",
    "]\n",
    "\n",
    "# 좌표 dtype 강제 숫자화 (중요!)\n",
    "test_x_num = pd.to_numeric(test_x, errors=\"coerce\")\n",
    "test_y_num = pd.to_numeric(test_y, errors=\"coerce\")\n",
    "\n",
    "xy = np.stack([test_x_num, test_y_num], axis=1)\n",
    "valid = np.isfinite(xy).all(axis=1)\n",
    "dt = clean_detail_arr(test_detail)\n",
    "\n",
    "print(\"valid xy:\", valid.sum(), \"/\", len(valid))\n",
    "\n",
    "detail_report = []\n",
    "\n",
    "for ROAD in DETAIL_ROADS:\n",
    "    print(f\"\\n[ROAD] {ROAD}\")\n",
    "\n",
    "    road_knn_path = os.path.join(KNN_ROOT, ROAD, \"knn_road.pkl\")\n",
    "    if not os.path.exists(road_knn_path):\n",
    "        print(\"  ❗ road knn not found:\", road_knn_path)\n",
    "        continue\n",
    "\n",
    "    knn_road = joblib.load(road_knn_path)\n",
    "\n",
    "    # 이 도로에 존재하는 detail 목록 (test 기준)\n",
    "    details_in_road = sorted(list(set(dt[test_road_label == ROAD])))\n",
    "    details_in_road = [d for d in details_in_road if d != \"0\"]\n",
    "    print(\"  details:\", details_in_road)\n",
    "\n",
    "    for DETAIL in details_in_road:\n",
    "        detail_knn_path = os.path.join(KNN_ROOT, ROAD, f\"knn_detail_{DETAIL}.pkl\")\n",
    "        if not os.path.exists(detail_knn_path):\n",
    "            print(f\"    ❗ detail knn not found: {DETAIL}\")\n",
    "            continue\n",
    "\n",
    "        idx = np.where((test_road_label == ROAD) & (dt == DETAIL) & valid)[0]\n",
    "        print(f\"    detail={DETAIL} | valid samples={len(idx)}\")\n",
    "\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "\n",
    "        knn_detail = joblib.load(detail_knn_path)\n",
    "\n",
    "        Z = make_knn_Z(X_hog_test[idx], X_color_test[idx])\n",
    "        gt_xy = xy[idx]\n",
    "\n",
    "        pred_r = knn_road.predict(Z)\n",
    "        pred_d = knn_detail.predict(Z)\n",
    "\n",
    "        dist_r = euclid_dist(pred_r, gt_xy)\n",
    "        dist_d = euclid_dist(pred_d, gt_xy)\n",
    "\n",
    "        detail_report.append({\n",
    "            \"road\": ROAD,\n",
    "            \"detail\": DETAIL,\n",
    "            \"n\": len(idx),\n",
    "            \"road_mean\": float(dist_r.mean()),\n",
    "            \"detail_mean\": float(dist_d.mean()),\n",
    "            \"road_median\": float(np.median(dist_r)),\n",
    "            \"detail_median\": float(np.median(dist_d)),\n",
    "            \"mean_improve\": float(dist_r.mean() - dist_d.mean()),\n",
    "            \"median_improve\": float(np.median(dist_r) - np.median(dist_d)),\n",
    "        })\n",
    "\n",
    "print(\"\\n=== detail_report rows ===\", len(detail_report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detail KNN Distance Report (per detail) ===\n",
      "donhwamunro_11_da | detail=A | n= 30 | road_mean=0.833 -> detail_mean=0.336 | Δmean=+0.497 | road_med=0.671 -> detail_med=0.327 | Δmed=+0.345\n",
      "donhwamunro_11_da | detail=B | n= 16 | road_mean=0.858 -> detail_mean=0.496 | Δmean=+0.362 | road_med=0.803 -> detail_med=0.456 | Δmed=+0.347\n",
      "donhwamunro_11_da | detail=C | n= 12 | road_mean=1.074 -> detail_mean=0.264 | Δmean=+0.810 | road_med=1.079 -> detail_med=0.000 | Δmed=+1.079\n",
      "donhwamunro_11_ga | detail=A | n= 16 | road_mean=2.164 -> detail_mean=0.307 | Δmean=+1.857 | road_med=2.247 -> detail_med=0.310 | Δmed=+1.937\n",
      "donhwamunro_11_ga | detail=B | n= 27 | road_mean=1.176 -> detail_mean=0.635 | Δmean=+0.542 | road_med=1.167 -> detail_med=0.484 | Δmed=+0.683\n",
      "donhwamunro_11_ga | detail=C | n= 29 | road_mean=0.980 -> detail_mean=0.290 | Δmean=+0.690 | road_med=0.760 -> detail_med=0.000 | Δmed=+0.760\n",
      "donhwamunro_11_na | detail=A | n= 23 | road_mean=1.864 -> detail_mean=0.603 | Δmean=+1.261 | road_med=1.973 -> detail_med=0.666 | Δmed=+1.307\n",
      "donhwamunro_11_na | detail=B | n= 42 | road_mean=0.980 -> detail_mean=0.410 | Δmean=+0.569 | road_med=0.758 -> detail_med=0.321 | Δmed=+0.437\n",
      "donhwamunro_11_na | detail=C | n= 18 | road_mean=1.033 -> detail_mean=0.000 | Δmean=+1.033 | road_med=0.932 -> detail_med=0.000 | Δmed=+0.932\n",
      "donhwamunro_11_na | detail=D | n= 17 | road_mean=1.795 -> detail_mean=0.225 | Δmean=+1.570 | road_med=1.882 -> detail_med=0.000 | Δmed=+1.882\n",
      "suporo_28       | detail=A | n= 35 | road_mean=1.214 -> detail_mean=0.900 | Δmean=+0.313 | road_med=1.146 -> detail_med=0.705 | Δmed=+0.441\n",
      "suporo_28       | detail=B | n= 20 | road_mean=0.868 -> detail_mean=0.459 | Δmean=+0.409 | road_med=0.752 -> detail_med=0.331 | Δmed=+0.422\n",
      "suporo_28       | detail=C | n= 12 | road_mean=0.500 -> detail_mean=0.290 | Δmean=+0.210 | road_med=0.541 -> detail_med=0.282 | Δmed=+0.259\n",
      "suporo_28       | detail=D | n= 20 | road_mean=1.019 -> detail_mean=0.431 | Δmean=+0.588 | road_med=0.968 -> detail_med=0.337 | Δmed=+0.631\n",
      "suporo_28       | detail=E | n= 10 | road_mean=1.417 -> detail_mean=0.000 | Δmean=+1.417 | road_med=1.811 -> detail_med=0.000 | Δmed=+1.811\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Detail KNN Distance Report (per detail) ===\")\n",
    "\n",
    "detail_report_sorted = sorted(detail_report, key=lambda x: (x[\"road\"], x[\"detail\"]))\n",
    "\n",
    "for r in detail_report_sorted:\n",
    "    print(\n",
    "        f\"{r['road']:15s} | detail={r['detail']} | n={r['n']:3d} | \"\n",
    "        f\"road_mean={r['road_mean']:.3f} -> detail_mean={r['detail_mean']:.3f} | \"\n",
    "        f\"Δmean={r['mean_improve']:+.3f} | \"\n",
    "        f\"road_med={r['road_median']:.3f} -> detail_med={r['detail_median']:.3f} | \"\n",
    "        f\"Δmed={r['median_improve']:+.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== k sweep (train → test) ===\n",
      "k=1 | mean=2.049 | median=1.414 | p90=5.099\n",
      "k=3 | mean=2.244 | median=1.948 | p90=4.447\n",
      "k=5 | mean=2.307 | median=2.200 | p90=4.115\n",
      "k=7 | mean=2.335 | median=2.147 | p90=4.086\n",
      "k=9 | mean=2.364 | median=2.218 | p90=4.020\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "K_LIST = [1, 3, 5, 7, 9]\n",
    "\n",
    "# train / test 좌표\n",
    "xy_train = np.stack([training_x, training_y], axis=1)\n",
    "xy_test  = np.stack([test_x, test_y], axis=1)\n",
    "\n",
    "valid_tr = np.isfinite(xy_train).all(axis=1)\n",
    "valid_te = np.isfinite(xy_test).all(axis=1)\n",
    "\n",
    "Z_train = make_knn_Z(X_hog_train, X_color_train)\n",
    "Z_test  = make_knn_Z(X_hog_test,  X_color_test)\n",
    "\n",
    "print(\"=== k sweep (train → test) ===\")\n",
    "\n",
    "for k in K_LIST:\n",
    "    knn = KNeighborsRegressor(\n",
    "        n_neighbors=k,\n",
    "        metric=\"euclidean\",\n",
    "        weights=\"distance\"\n",
    "    )\n",
    "\n",
    "    knn.fit(Z_train[valid_tr], xy_train[valid_tr])\n",
    "\n",
    "    pred = knn.predict(Z_test[valid_te])\n",
    "    dist = euclid_dist(pred, xy_test[valid_te])\n",
    "\n",
    "    print(\n",
    "        f\"k={k} | \"\n",
    "        f\"mean={dist.mean():.3f} | \"\n",
    "        f\"median={np.median(dist):.3f} | \"\n",
    "        f\"p90={np.percentile(dist,90):.3f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
